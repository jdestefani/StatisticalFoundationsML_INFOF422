{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Jacopo De Stefani - __[Jacopo.De.Stefani@ulb.ac.be](mailto:Jacopo.De.Stefani@ulb.ac.be)__\n",
    "### Théo Verhelst - __[Theo.Verhelst@ulb.ac.be](mailto:Theo.Verhelst@ulb.ac.be)__\n",
    "### Gianluca Bontempi - __[gbonte@ulb.ac.be](mailto:gbonte@ulb.ac.be)__\n",
    "\n",
    "## TP 5 - Ensembles of models and feature selection\n",
    "\n",
    "####  April 20, 2021\n",
    "\n",
    "#### Materials originally developed by *Yann-Aël Le Borgne, Fabrizio Carcillo and Gianluca Bontempi*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Feature selection and ensembles of models are two techniques which can be used to improve the accuracy of preditions. \n",
    "\n",
    "Feature selection aims at reducing the dimensionality of the problem, and is useful when input variables contain redundant or irrelevant (noisy) information. Benefits are twofold: it decreases the training time by simplifying the problem, and it decreases the complexity of the predictive model. This in turn usually improves the prediction accuracy, since high-dimensionality makes predictive models more prone to overfitting, and estimates of parameters more variant. \n",
    "\n",
    "There are three main approaches to feature selection:\n",
    "- **Filter methods:** \n",
    "These methods relies solely on the data and their intrinsic properties, without considering the impact of the selected features on the learning algorithm performance. For this reason, they are often used as preprocessing techniques.\n",
    "- **Wrapper methods:** \n",
    "These methods assess subsets of variables according to their usefulness to a given predictor. The feature selection is perfomed using an evaluation function that includes the predictive performance of the consider learning algorithm as a selection criterion. \n",
    "- **Embedded methods:** \n",
    "These methods are specific to given learning machines, and usually built-in in the learning procedure (e.g. random forest, regularization based techniques).\n",
    "\n",
    "Ensembles of models consist in building several predictive models using resampled subsets of the original training set. The method works particularly well for predictive models with high variance (for example, decision trees or neural networks). The average prediction of the resulting models usually strongly decreases the variance component of the error, and as a consequence improves the prediction accuracy. \n",
    "\n",
    "In this session, we will illustrate both techniques using the IMDB 5000 dataset, which contains 27 variables describing 5043 movies. The variables contain information about the director, actors, number of Facebook likes for each actor, duration, genre, language, country, etc... We will use them to predict the movie success (through the IMDB score). The dataset together with a description of the variables is at https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset.\n",
    "\n",
    "The dataset is on the github of the course, in `5_EnsemblesFeatureSelection/movie_metadata.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "The process of supervised learning involves the presence of an entity (the learner, also called prediction model), whose goal is to learn the mapping between inputs and outputs in a given problem.\n",
    "\n",
    "A supervised learning problem can formulated as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    " y = m(\\mathbf{x})  \n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    "- $y$ represents the output variable (also called target)\n",
    "- $\\mathbf{x}$ represents the vector of inputs (also called features).\n",
    "- $m$ is the (unknown) mapping between input and outputs.\n",
    "\n",
    "In the majority of the supervised learning problems, the mapping $m$ between input and outputs is unknown and needs to be estimated on basis of the available input/output observation pairs $(\\mathbf{x}_i,y_i)$.\n",
    "\n",
    "## Classification vs regression\n",
    "\n",
    "Both classification and regression are sub-fields of *supervised learning*. In the two cases, we have predictive variables $\\mathbf{x}$ and a target variable $y$. \n",
    "The main difference betweet the two type of problems is the type of the target variabile:\n",
    "\n",
    "- In classification, $y$ is a discrete variable; i.e $y \\in \\{C_1,\\cdots,C_k\\}$\n",
    "- In regression, $y$ is a continuous variable; i.e $y \\in \\mathbb{R}$\n",
    "\n",
    "In this practical, unlike the previous ones, we will tackle our problem as a regression problem, with the IMDB score being the continuous target variable to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load and select a random subset of 1000 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data<-read.csv(\"movie_metadata.csv\",stringsAsFactors = T)\n",
    "set.seed(2)\n",
    "data<-data[sample(nrow(data),1000),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1000</li><li>28</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 28\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 28\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 28</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>color</th><th scope=col>director_name</th><th scope=col>num_critic_for_reviews</th><th scope=col>duration</th><th scope=col>director_facebook_likes</th><th scope=col>actor_3_facebook_likes</th><th scope=col>actor_2_name</th><th scope=col>actor_1_facebook_likes</th><th scope=col>gross</th><th scope=col>genres</th><th scope=col>actor_1_name</th><th scope=col>movie_title</th><th scope=col>num_voted_users</th><th scope=col>cast_total_facebook_likes</th><th scope=col>actor_3_name</th><th scope=col>facenumber_in_poster</th><th scope=col>plot_keywords</th><th scope=col>movie_imdb_link</th><th scope=col>num_user_for_reviews</th><th scope=col>language</th><th scope=col>country</th><th scope=col>content_rating</th><th scope=col>budget</th><th scope=col>title_year</th><th scope=col>actor_2_facebook_likes</th><th scope=col>imdb_score</th><th scope=col>aspect_ratio</th><th scope=col>movie_facebook_likes</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3925</th><td>Color</td><td>Oliver Stone</td><td>40</td><td>110</td><td>0</td><td>237</td><td>Zach Grenier</td><td>721</td><td>3468572</td><td>Drama          </td><td>Michael Wincott</td><td>Talk RadioÂ     </td><td>10073</td><td>1966</td><td>Bill Johnson </td><td>0</td><td>listener|neo nazi|radio|radio station|radio talk show</td><td>http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1</td><td>78</td><td>English</td><td>USA   </td><td>R</td><td>4e+06</td><td>1988</td><td>246</td><td>7.3</td><td>1.85</td><td>816</td></tr>\n",
       "\t<tr><th scope=row>4806</th><td>Color</td><td>Paul Fox    </td><td>80</td><td> 80</td><td>3</td><td> 39</td><td>Jeff Seymour</td><td>108</td><td>     NA</td><td>Horror|Thriller</td><td>Dov Tiefenbach </td><td>The Dark HoursÂ </td><td> 4788</td><td> 272</td><td>Gordon Currie</td><td>0</td><td>brain tumor|champagne|game|psychiatrist|weekend      </td><td>http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1</td><td>52</td><td>English</td><td>Canada</td><td>R</td><td>5e+05</td><td>2005</td><td> 64</td><td>6.1</td><td>1.85</td><td>166</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 28\n",
       "\\begin{tabular}{r|llllllllllllllllllllllllllll}\n",
       "  & color & director\\_name & num\\_critic\\_for\\_reviews & duration & director\\_facebook\\_likes & actor\\_3\\_facebook\\_likes & actor\\_2\\_name & actor\\_1\\_facebook\\_likes & gross & genres & actor\\_1\\_name & movie\\_title & num\\_voted\\_users & cast\\_total\\_facebook\\_likes & actor\\_3\\_name & facenumber\\_in\\_poster & plot\\_keywords & movie\\_imdb\\_link & num\\_user\\_for\\_reviews & language & country & content\\_rating & budget & title\\_year & actor\\_2\\_facebook\\_likes & imdb\\_score & aspect\\_ratio & movie\\_facebook\\_likes\\\\\n",
       "  & <fct> & <fct> & <int> & <int> & <int> & <int> & <fct> & <int> & <int> & <fct> & <fct> & <fct> & <int> & <int> & <fct> & <int> & <fct> & <fct> & <int> & <fct> & <fct> & <fct> & <dbl> & <int> & <int> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t3925 & Color & Oliver Stone & 40 & 110 & 0 & 237 & Zach Grenier & 721 & 3468572 & Drama           & Michael Wincott & Talk RadioÂ      & 10073 & 1966 & Bill Johnson  & 0 & listener\\textbar{}neo nazi\\textbar{}radio\\textbar{}radio station\\textbar{}radio talk show & http://www.imdb.com/title/tt0096219/?ref\\_=fn\\_tt\\_tt\\_1 & 78 & English & USA    & R & 4e+06 & 1988 & 246 & 7.3 & 1.85 & 816\\\\\n",
       "\t4806 & Color & Paul Fox     & 80 &  80 & 3 &  39 & Jeff Seymour & 108 &      NA & Horror\\textbar{}Thriller & Dov Tiefenbach  & The Dark HoursÂ  &  4788 &  272 & Gordon Currie & 0 & brain tumor\\textbar{}champagne\\textbar{}game\\textbar{}psychiatrist\\textbar{}weekend       & http://www.imdb.com/title/tt0402249/?ref\\_=fn\\_tt\\_tt\\_1 & 52 & English & Canada & R & 5e+05 & 2005 &  64 & 6.1 & 1.85 & 166\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 28\n",
       "\n",
       "| <!--/--> | color &lt;fct&gt; | director_name &lt;fct&gt; | num_critic_for_reviews &lt;int&gt; | duration &lt;int&gt; | director_facebook_likes &lt;int&gt; | actor_3_facebook_likes &lt;int&gt; | actor_2_name &lt;fct&gt; | actor_1_facebook_likes &lt;int&gt; | gross &lt;int&gt; | genres &lt;fct&gt; | actor_1_name &lt;fct&gt; | movie_title &lt;fct&gt; | num_voted_users &lt;int&gt; | cast_total_facebook_likes &lt;int&gt; | actor_3_name &lt;fct&gt; | facenumber_in_poster &lt;int&gt; | plot_keywords &lt;fct&gt; | movie_imdb_link &lt;fct&gt; | num_user_for_reviews &lt;int&gt; | language &lt;fct&gt; | country &lt;fct&gt; | content_rating &lt;fct&gt; | budget &lt;dbl&gt; | title_year &lt;int&gt; | actor_2_facebook_likes &lt;int&gt; | imdb_score &lt;dbl&gt; | aspect_ratio &lt;dbl&gt; | movie_facebook_likes &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3925 | Color | Oliver Stone | 40 | 110 | 0 | 237 | Zach Grenier | 721 | 3468572 | Drama           | Michael Wincott | Talk RadioÂ      | 10073 | 1966 | Bill Johnson  | 0 | listener|neo nazi|radio|radio station|radio talk show | http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1 | 78 | English | USA    | R | 4e+06 | 1988 | 246 | 7.3 | 1.85 | 816 |\n",
       "| 4806 | Color | Paul Fox     | 80 |  80 | 3 |  39 | Jeff Seymour | 108 |      NA | Horror|Thriller | Dov Tiefenbach  | The Dark HoursÂ  |  4788 |  272 | Gordon Currie | 0 | brain tumor|champagne|game|psychiatrist|weekend       | http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1 | 52 | English | Canada | R | 5e+05 | 2005 |  64 | 6.1 | 1.85 | 166 |\n",
       "\n"
      ],
      "text/plain": [
       "     color director_name num_critic_for_reviews duration\n",
       "3925 Color Oliver Stone  40                     110     \n",
       "4806 Color Paul Fox      80                      80     \n",
       "     director_facebook_likes actor_3_facebook_likes actor_2_name\n",
       "3925 0                       237                    Zach Grenier\n",
       "4806 3                        39                    Jeff Seymour\n",
       "     actor_1_facebook_likes gross   genres          actor_1_name   \n",
       "3925 721                    3468572 Drama           Michael Wincott\n",
       "4806 108                         NA Horror|Thriller Dov Tiefenbach \n",
       "     movie_title      num_voted_users cast_total_facebook_likes actor_3_name \n",
       "3925 Talk RadioÂ      10073           1966                      Bill Johnson \n",
       "4806 The Dark HoursÂ   4788            272                      Gordon Currie\n",
       "     facenumber_in_poster plot_keywords                                        \n",
       "3925 0                    listener|neo nazi|radio|radio station|radio talk show\n",
       "4806 0                    brain tumor|champagne|game|psychiatrist|weekend      \n",
       "     movie_imdb_link                                      num_user_for_reviews\n",
       "3925 http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1 78                  \n",
       "4806 http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1 52                  \n",
       "     language country content_rating budget title_year actor_2_facebook_likes\n",
       "3925 English  USA     R              4e+06  1988       246                   \n",
       "4806 English  Canada  R              5e+05  2005        64                   \n",
       "     imdb_score aspect_ratio movie_facebook_likes\n",
       "3925 7.3        1.85         816                 \n",
       "4806 6.1        1.85         166                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.matrix.max.cols=50)\n",
    "data[1:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              color              director_name num_critic_for_reviews\n",
       "                 :  4                   : 24   Min.   :  1.0         \n",
       "  Black and White: 37   Woody Allen     :  7   1st Qu.: 48.0         \n",
       " Color           :959   Bobby Farrelly  :  6   Median :103.0         \n",
       "                        Barry Levinson  :  5   Mean   :135.1         \n",
       "                        Chris Columbus  :  5   3rd Qu.:184.2         \n",
       "                        Steven Spielberg:  5   Max.   :765.0         \n",
       "                        (Other)         :948   NA's   :16            \n",
       "    duration   director_facebook_likes actor_3_facebook_likes\n",
       " Min.   :  7   Min.   :    0.00        Min.   :    0.0       \n",
       " 1st Qu.: 93   1st Qu.:    6.75        1st Qu.:  120.0       \n",
       " Median :103   Median :   44.00        Median :  395.0       \n",
       " Mean   :106   Mean   :  669.26        Mean   :  602.2       \n",
       " 3rd Qu.:116   3rd Qu.:  204.75        3rd Qu.:  642.0       \n",
       " Max.   :511   Max.   :21000.00        Max.   :19000.0       \n",
       " NA's   :4     NA's   :24              NA's   :5             \n",
       "          actor_2_name actor_1_facebook_likes     gross          \n",
       "                :  4   Min.   :    0          Min.   :      703  \n",
       " Adam Sandler   :  4   1st Qu.:  623          1st Qu.:  5003486  \n",
       " James Franco   :  4   Median :  979          Median : 25025352  \n",
       " Monica Potter  :  4   Mean   : 5951          Mean   : 46927291  \n",
       " Morgan Freeman :  4   3rd Qu.:11000          3rd Qu.: 60549232  \n",
       " Zooey Deschanel:  4   Max.   :49000          Max.   :658672302  \n",
       " (Other)        :976   NA's   :3              NA's   :200        \n",
       "                  genres               actor_1_name\n",
       " Drama               : 55   Johnny Depp      : 10  \n",
       " Comedy|Drama        : 49   Bruce Willis     :  9  \n",
       " Comedy              : 40   Keanu Reeves     :  8  \n",
       " Drama|Romance       : 33   Morgan Freeman   :  8  \n",
       " Comedy|Romance      : 32   Robert De Niro   :  8  \n",
       " Comedy|Drama|Romance: 29   Denzel Washington:  7  \n",
       " (Other)             :762   (Other)          :950  \n",
       "                         movie_title  num_voted_users \n",
       " History of the World: Part IÂ :  2   Min.   :     5  \n",
       " PoltergeistÂ                  :  2   1st Qu.:  7110  \n",
       " PreciousÂ                     :  2   Median : 31625  \n",
       " The GamblerÂ                  :  2   Mean   : 76398  \n",
       " The Last House on the LeftÂ   :  2   3rd Qu.: 87767  \n",
       " 10 Days in a MadhouseÂ        :  1   Max.   :955174  \n",
       " (Other)                       :989                   \n",
       " cast_total_facebook_likes       actor_3_name facenumber_in_poster\n",
       " Min.   :    0                         :  5   Min.   : 0.000      \n",
       " 1st Qu.: 1466             Beth Grant  :  3   1st Qu.: 0.000      \n",
       " Median : 3142             Cheech Marin:  3   Median : 1.000      \n",
       " Mean   : 9103             Ellen Barkin:  3   Mean   : 1.394      \n",
       " 3rd Qu.:13884             Faizon Love :  3   3rd Qu.: 2.000      \n",
       " Max.   :77823             Franco Nero :  3   Max.   :31.000      \n",
       "                           (Other)     :980   NA's   :2           \n",
       "                                                                                            plot_keywords\n",
       "                                                                                                   : 37  \n",
       " abuse|african american lesbian|lesbian|lesbian couple|school                                      :  2  \n",
       " based on novel                                                                                    :  2  \n",
       " dog|gambler|gambling|gangster|professor                                                           :  2  \n",
       " french revolution|old testament|part of an unfinished series|reference to john wayne|roman emperor:  2  \n",
       " ghost|haunted|haunting|house|paranormal investigator                                              :  2  \n",
       " (Other)                                                                                           :953  \n",
       "                                             movie_imdb_link\n",
       " http://www.imdb.com/title/tt0082517/?ref_=fn_tt_tt_1:  2   \n",
       " http://www.imdb.com/title/tt0084516/?ref_=fn_tt_tt_1:  2   \n",
       " http://www.imdb.com/title/tt0844708/?ref_=fn_tt_tt_1:  2   \n",
       " http://www.imdb.com/title/tt0929632/?ref_=fn_tt_tt_1:  2   \n",
       " http://www.imdb.com/title/tt2039393/?ref_=fn_tt_tt_1:  2   \n",
       " http://www.imdb.com/title/tt0006864/?ref_=fn_tt_tt_1:  1   \n",
       " (Other)                                             :989   \n",
       " num_user_for_reviews    language        country      content_rating\n",
       " Min.   :   1.00      English:934   USA      :752   R        :433   \n",
       " 1st Qu.:  60.25      French : 15   UK       : 98   PG-13    :264   \n",
       " Median : 154.50      Hindi  :  5   Canada   : 27   PG       :145   \n",
       " Mean   : 257.51      Spanish:  5   France   : 24            : 78   \n",
       " 3rd Qu.: 316.00             :  4   Germany  : 20   Not Rated: 21   \n",
       " Max.   :3597.00      German :  4   Australia: 18   G        : 11   \n",
       " NA's   :6            (Other): 33   (Other)  : 61   (Other)  : 48   \n",
       "     budget            title_year   actor_2_facebook_likes   imdb_score   \n",
       " Min.   :     3250   Min.   :1916   Min.   :    0.0        Min.   :1.900  \n",
       " 1st Qu.:  5000000   1st Qu.:1999   1st Qu.:  299.8        1st Qu.:5.800  \n",
       " Median : 18013074   Median :2005   Median :  602.0        Median :6.500  \n",
       " Mean   : 31645256   Mean   :2002   Mean   : 1720.3        Mean   :6.426  \n",
       " 3rd Qu.: 40000000   3rd Qu.:2011   3rd Qu.:  934.0        3rd Qu.:7.200  \n",
       " Max.   :260000000   Max.   :2016   Max.   :29000.0        Max.   :8.900  \n",
       " NA's   :104         NA's   :24     NA's   :4                             \n",
       "  aspect_ratio    movie_facebook_likes\n",
       " Min.   : 1.330   Min.   :     0      \n",
       " 1st Qu.: 1.850   1st Qu.:     0      \n",
       " Median : 2.350   Median :    65      \n",
       " Mean   : 2.289   Mean   :  6947      \n",
       " 3rd Qu.: 2.350   3rd Qu.:  1000      \n",
       " Max.   :16.000   Max.   :199000      \n",
       " NA's   :80                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is a mix of categorical and numerical variables, and some missing values. In order to simplify the analysis, let us remove the categorical variables, and replace the NA values with the mean values of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>color</dt><dd>'factor'</dd><dt>director_name</dt><dd>'factor'</dd><dt>num_critic_for_reviews</dt><dd>'integer'</dd><dt>duration</dt><dd>'integer'</dd><dt>director_facebook_likes</dt><dd>'integer'</dd><dt>actor_3_facebook_likes</dt><dd>'integer'</dd><dt>actor_2_name</dt><dd>'factor'</dd><dt>actor_1_facebook_likes</dt><dd>'integer'</dd><dt>gross</dt><dd>'integer'</dd><dt>genres</dt><dd>'factor'</dd><dt>actor_1_name</dt><dd>'factor'</dd><dt>movie_title</dt><dd>'factor'</dd><dt>num_voted_users</dt><dd>'integer'</dd><dt>cast_total_facebook_likes</dt><dd>'integer'</dd><dt>actor_3_name</dt><dd>'factor'</dd><dt>facenumber_in_poster</dt><dd>'integer'</dd><dt>plot_keywords</dt><dd>'factor'</dd><dt>movie_imdb_link</dt><dd>'factor'</dd><dt>num_user_for_reviews</dt><dd>'integer'</dd><dt>language</dt><dd>'factor'</dd><dt>country</dt><dd>'factor'</dd><dt>content_rating</dt><dd>'factor'</dd><dt>budget</dt><dd>'numeric'</dd><dt>title_year</dt><dd>'integer'</dd><dt>actor_2_facebook_likes</dt><dd>'integer'</dd><dt>imdb_score</dt><dd>'numeric'</dd><dt>aspect_ratio</dt><dd>'numeric'</dd><dt>movie_facebook_likes</dt><dd>'integer'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[color] 'factor'\n",
       "\\item[director\\textbackslash{}\\_name] 'factor'\n",
       "\\item[num\\textbackslash{}\\_critic\\textbackslash{}\\_for\\textbackslash{}\\_reviews] 'integer'\n",
       "\\item[duration] 'integer'\n",
       "\\item[director\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_name] 'factor'\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[gross] 'integer'\n",
       "\\item[genres] 'factor'\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_name] 'factor'\n",
       "\\item[movie\\textbackslash{}\\_title] 'factor'\n",
       "\\item[num\\textbackslash{}\\_voted\\textbackslash{}\\_users] 'integer'\n",
       "\\item[cast\\textbackslash{}\\_total\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_name] 'factor'\n",
       "\\item[facenumber\\textbackslash{}\\_in\\textbackslash{}\\_poster] 'integer'\n",
       "\\item[plot\\textbackslash{}\\_keywords] 'factor'\n",
       "\\item[movie\\textbackslash{}\\_imdb\\textbackslash{}\\_link] 'factor'\n",
       "\\item[num\\textbackslash{}\\_user\\textbackslash{}\\_for\\textbackslash{}\\_reviews] 'integer'\n",
       "\\item[language] 'factor'\n",
       "\\item[country] 'factor'\n",
       "\\item[content\\textbackslash{}\\_rating] 'factor'\n",
       "\\item[budget] 'numeric'\n",
       "\\item[title\\textbackslash{}\\_year] 'integer'\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\item[imdb\\textbackslash{}\\_score] 'numeric'\n",
       "\\item[aspect\\textbackslash{}\\_ratio] 'numeric'\n",
       "\\item[movie\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] 'integer'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "color\n",
       ":   'factor'director_name\n",
       ":   'factor'num_critic_for_reviews\n",
       ":   'integer'duration\n",
       ":   'integer'director_facebook_likes\n",
       ":   'integer'actor_3_facebook_likes\n",
       ":   'integer'actor_2_name\n",
       ":   'factor'actor_1_facebook_likes\n",
       ":   'integer'gross\n",
       ":   'integer'genres\n",
       ":   'factor'actor_1_name\n",
       ":   'factor'movie_title\n",
       ":   'factor'num_voted_users\n",
       ":   'integer'cast_total_facebook_likes\n",
       ":   'integer'actor_3_name\n",
       ":   'factor'facenumber_in_poster\n",
       ":   'integer'plot_keywords\n",
       ":   'factor'movie_imdb_link\n",
       ":   'factor'num_user_for_reviews\n",
       ":   'integer'language\n",
       ":   'factor'country\n",
       ":   'factor'content_rating\n",
       ":   'factor'budget\n",
       ":   'numeric'title_year\n",
       ":   'integer'actor_2_facebook_likes\n",
       ":   'integer'imdb_score\n",
       ":   'numeric'aspect_ratio\n",
       ":   'numeric'movie_facebook_likes\n",
       ":   'integer'\n",
       "\n"
      ],
      "text/plain": [
       "                    color             director_name    num_critic_for_reviews \n",
       "                 \"factor\"                  \"factor\"                 \"integer\" \n",
       "                 duration   director_facebook_likes    actor_3_facebook_likes \n",
       "                \"integer\"                 \"integer\"                 \"integer\" \n",
       "             actor_2_name    actor_1_facebook_likes                     gross \n",
       "                 \"factor\"                 \"integer\"                 \"integer\" \n",
       "                   genres              actor_1_name               movie_title \n",
       "                 \"factor\"                  \"factor\"                  \"factor\" \n",
       "          num_voted_users cast_total_facebook_likes              actor_3_name \n",
       "                \"integer\"                 \"integer\"                  \"factor\" \n",
       "     facenumber_in_poster             plot_keywords           movie_imdb_link \n",
       "                \"integer\"                  \"factor\"                  \"factor\" \n",
       "     num_user_for_reviews                  language                   country \n",
       "                \"integer\"                  \"factor\"                  \"factor\" \n",
       "           content_rating                    budget                title_year \n",
       "                 \"factor\"                 \"numeric\"                 \"integer\" \n",
       "   actor_2_facebook_likes                imdb_score              aspect_ratio \n",
       "                \"integer\"                 \"numeric\"                 \"numeric\" \n",
       "     movie_facebook_likes \n",
       "                \"integer\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sapply(data[1,],class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of categorical (factor) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>color</dt><dd>TRUE</dd><dt>director_name</dt><dd>TRUE</dd><dt>num_critic_for_reviews</dt><dd>FALSE</dd><dt>duration</dt><dd>FALSE</dd><dt>director_facebook_likes</dt><dd>FALSE</dd><dt>actor_3_facebook_likes</dt><dd>FALSE</dd><dt>actor_2_name</dt><dd>TRUE</dd><dt>actor_1_facebook_likes</dt><dd>FALSE</dd><dt>gross</dt><dd>FALSE</dd><dt>genres</dt><dd>TRUE</dd><dt>actor_1_name</dt><dd>TRUE</dd><dt>movie_title</dt><dd>TRUE</dd><dt>num_voted_users</dt><dd>FALSE</dd><dt>cast_total_facebook_likes</dt><dd>FALSE</dd><dt>actor_3_name</dt><dd>TRUE</dd><dt>facenumber_in_poster</dt><dd>FALSE</dd><dt>plot_keywords</dt><dd>TRUE</dd><dt>movie_imdb_link</dt><dd>TRUE</dd><dt>num_user_for_reviews</dt><dd>FALSE</dd><dt>language</dt><dd>TRUE</dd><dt>country</dt><dd>TRUE</dd><dt>content_rating</dt><dd>TRUE</dd><dt>budget</dt><dd>FALSE</dd><dt>title_year</dt><dd>FALSE</dd><dt>actor_2_facebook_likes</dt><dd>FALSE</dd><dt>imdb_score</dt><dd>FALSE</dd><dt>aspect_ratio</dt><dd>FALSE</dd><dt>movie_facebook_likes</dt><dd>FALSE</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[color] TRUE\n",
       "\\item[director\\textbackslash{}\\_name] TRUE\n",
       "\\item[num\\textbackslash{}\\_critic\\textbackslash{}\\_for\\textbackslash{}\\_reviews] FALSE\n",
       "\\item[duration] FALSE\n",
       "\\item[director\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] FALSE\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] FALSE\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_name] TRUE\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] FALSE\n",
       "\\item[gross] FALSE\n",
       "\\item[genres] TRUE\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_name] TRUE\n",
       "\\item[movie\\textbackslash{}\\_title] TRUE\n",
       "\\item[num\\textbackslash{}\\_voted\\textbackslash{}\\_users] FALSE\n",
       "\\item[cast\\textbackslash{}\\_total\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] FALSE\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_name] TRUE\n",
       "\\item[facenumber\\textbackslash{}\\_in\\textbackslash{}\\_poster] FALSE\n",
       "\\item[plot\\textbackslash{}\\_keywords] TRUE\n",
       "\\item[movie\\textbackslash{}\\_imdb\\textbackslash{}\\_link] TRUE\n",
       "\\item[num\\textbackslash{}\\_user\\textbackslash{}\\_for\\textbackslash{}\\_reviews] FALSE\n",
       "\\item[language] TRUE\n",
       "\\item[country] TRUE\n",
       "\\item[content\\textbackslash{}\\_rating] TRUE\n",
       "\\item[budget] FALSE\n",
       "\\item[title\\textbackslash{}\\_year] FALSE\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] FALSE\n",
       "\\item[imdb\\textbackslash{}\\_score] FALSE\n",
       "\\item[aspect\\textbackslash{}\\_ratio] FALSE\n",
       "\\item[movie\\textbackslash{}\\_facebook\\textbackslash{}\\_likes] FALSE\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "color\n",
       ":   TRUEdirector_name\n",
       ":   TRUEnum_critic_for_reviews\n",
       ":   FALSEduration\n",
       ":   FALSEdirector_facebook_likes\n",
       ":   FALSEactor_3_facebook_likes\n",
       ":   FALSEactor_2_name\n",
       ":   TRUEactor_1_facebook_likes\n",
       ":   FALSEgross\n",
       ":   FALSEgenres\n",
       ":   TRUEactor_1_name\n",
       ":   TRUEmovie_title\n",
       ":   TRUEnum_voted_users\n",
       ":   FALSEcast_total_facebook_likes\n",
       ":   FALSEactor_3_name\n",
       ":   TRUEfacenumber_in_poster\n",
       ":   FALSEplot_keywords\n",
       ":   TRUEmovie_imdb_link\n",
       ":   TRUEnum_user_for_reviews\n",
       ":   FALSElanguage\n",
       ":   TRUEcountry\n",
       ":   TRUEcontent_rating\n",
       ":   TRUEbudget\n",
       ":   FALSEtitle_year\n",
       ":   FALSEactor_2_facebook_likes\n",
       ":   FALSEimdb_score\n",
       ":   FALSEaspect_ratio\n",
       ":   FALSEmovie_facebook_likes\n",
       ":   FALSE\n",
       "\n"
      ],
      "text/plain": [
       "                    color             director_name    num_critic_for_reviews \n",
       "                     TRUE                      TRUE                     FALSE \n",
       "                 duration   director_facebook_likes    actor_3_facebook_likes \n",
       "                    FALSE                     FALSE                     FALSE \n",
       "             actor_2_name    actor_1_facebook_likes                     gross \n",
       "                     TRUE                     FALSE                     FALSE \n",
       "                   genres              actor_1_name               movie_title \n",
       "                     TRUE                      TRUE                      TRUE \n",
       "          num_voted_users cast_total_facebook_likes              actor_3_name \n",
       "                    FALSE                     FALSE                      TRUE \n",
       "     facenumber_in_poster             plot_keywords           movie_imdb_link \n",
       "                    FALSE                      TRUE                      TRUE \n",
       "     num_user_for_reviews                  language                   country \n",
       "                    FALSE                      TRUE                      TRUE \n",
       "           content_rating                    budget                title_year \n",
       "                     TRUE                     FALSE                     FALSE \n",
       "   actor_2_facebook_likes                imdb_score              aspect_ratio \n",
       "                    FALSE                     FALSE                     FALSE \n",
       "     movie_facebook_likes \n",
       "                    FALSE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor_variables_bool<-sapply(data[1,],class)==\"factor\"\n",
    "factor_variables_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>color</dt><dd>1</dd><dt>director_name</dt><dd>2</dd><dt>actor_2_name</dt><dd>7</dd><dt>genres</dt><dd>10</dd><dt>actor_1_name</dt><dd>11</dd><dt>movie_title</dt><dd>12</dd><dt>actor_3_name</dt><dd>15</dd><dt>plot_keywords</dt><dd>17</dd><dt>movie_imdb_link</dt><dd>18</dd><dt>language</dt><dd>20</dd><dt>country</dt><dd>21</dd><dt>content_rating</dt><dd>22</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[color] 1\n",
       "\\item[director\\textbackslash{}\\_name] 2\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_name] 7\n",
       "\\item[genres] 10\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_name] 11\n",
       "\\item[movie\\textbackslash{}\\_title] 12\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_name] 15\n",
       "\\item[plot\\textbackslash{}\\_keywords] 17\n",
       "\\item[movie\\textbackslash{}\\_imdb\\textbackslash{}\\_link] 18\n",
       "\\item[language] 20\n",
       "\\item[country] 21\n",
       "\\item[content\\textbackslash{}\\_rating] 22\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "color\n",
       ":   1director_name\n",
       ":   2actor_2_name\n",
       ":   7genres\n",
       ":   10actor_1_name\n",
       ":   11movie_title\n",
       ":   12actor_3_name\n",
       ":   15plot_keywords\n",
       ":   17movie_imdb_link\n",
       ":   18language\n",
       ":   20country\n",
       ":   21content_rating\n",
       ":   22\n",
       "\n"
      ],
      "text/plain": [
       "          color   director_name    actor_2_name          genres    actor_1_name \n",
       "              1               2               7              10              11 \n",
       "    movie_title    actor_3_name   plot_keywords movie_imdb_link        language \n",
       "             12              15              17              18              20 \n",
       "        country  content_rating \n",
       "             21              22 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor_variables<-which(sapply(data[1,],class)==\"factor\")\n",
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " num_critic_for_reviews    duration   director_facebook_likes\n",
       " Min.   :  1.0          Min.   :  7   Min.   :    0.00       \n",
       " 1st Qu.: 48.0          1st Qu.: 93   1st Qu.:    6.75       \n",
       " Median :103.0          Median :103   Median :   44.00       \n",
       " Mean   :135.1          Mean   :106   Mean   :  669.26       \n",
       " 3rd Qu.:184.2          3rd Qu.:116   3rd Qu.:  204.75       \n",
       " Max.   :765.0          Max.   :511   Max.   :21000.00       \n",
       " NA's   :16             NA's   :4     NA's   :24             \n",
       " actor_3_facebook_likes actor_1_facebook_likes     gross          \n",
       " Min.   :    0.0        Min.   :    0          Min.   :      703  \n",
       " 1st Qu.:  120.0        1st Qu.:  623          1st Qu.:  5003486  \n",
       " Median :  395.0        Median :  979          Median : 25025352  \n",
       " Mean   :  602.2        Mean   : 5951          Mean   : 46927291  \n",
       " 3rd Qu.:  642.0        3rd Qu.:11000          3rd Qu.: 60549232  \n",
       " Max.   :19000.0        Max.   :49000          Max.   :658672302  \n",
       " NA's   :5              NA's   :3              NA's   :200        \n",
       " num_voted_users  cast_total_facebook_likes facenumber_in_poster\n",
       " Min.   :     5   Min.   :    0             Min.   : 0.000      \n",
       " 1st Qu.:  7110   1st Qu.: 1466             1st Qu.: 0.000      \n",
       " Median : 31625   Median : 3142             Median : 1.000      \n",
       " Mean   : 76398   Mean   : 9103             Mean   : 1.394      \n",
       " 3rd Qu.: 87767   3rd Qu.:13884             3rd Qu.: 2.000      \n",
       " Max.   :955174   Max.   :77823             Max.   :31.000      \n",
       "                                            NA's   :2           \n",
       " num_user_for_reviews     budget            title_year   actor_2_facebook_likes\n",
       " Min.   :   1.00      Min.   :     3250   Min.   :1916   Min.   :    0.0       \n",
       " 1st Qu.:  60.25      1st Qu.:  5000000   1st Qu.:1999   1st Qu.:  299.8       \n",
       " Median : 154.50      Median : 18013074   Median :2005   Median :  602.0       \n",
       " Mean   : 257.51      Mean   : 31645256   Mean   :2002   Mean   : 1720.3       \n",
       " 3rd Qu.: 316.00      3rd Qu.: 40000000   3rd Qu.:2011   3rd Qu.:  934.0       \n",
       " Max.   :3597.00      Max.   :260000000   Max.   :2016   Max.   :29000.0       \n",
       " NA's   :6            NA's   :104         NA's   :24     NA's   :4             \n",
       "   imdb_score     aspect_ratio    movie_facebook_likes\n",
       " Min.   :1.900   Min.   : 1.330   Min.   :     0      \n",
       " 1st Qu.:5.800   1st Qu.: 1.850   1st Qu.:     0      \n",
       " Median :6.500   Median : 2.350   Median :    65      \n",
       " Mean   :6.426   Mean   : 2.289   Mean   :  6947      \n",
       " 3rd Qu.:7.200   3rd Qu.: 2.350   3rd Qu.:  1000      \n",
       " Max.   :8.900   Max.   :16.000   Max.   :199000      \n",
       "                 NA's   :80                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_preprocessed<-data[,-factor_variables]\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NA values with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_na_with_mean_value<-function(vec) {\n",
    "    mean_vec<-mean(vec,na.rm=T)\n",
    "    vec[is.na(vec)]<-mean_vec\n",
    "    vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " num_critic_for_reviews    duration   director_facebook_likes\n",
       " Min.   :  1.0          Min.   :  7   Min.   :    0.0        \n",
       " 1st Qu.: 48.0          1st Qu.: 93   1st Qu.:    7.0        \n",
       " Median :105.5          Median :103   Median :   48.5        \n",
       " Mean   :135.1          Mean   :106   Mean   :  669.3        \n",
       " 3rd Qu.:181.0          3rd Qu.:116   3rd Qu.:  234.0        \n",
       " Max.   :765.0          Max.   :511   Max.   :21000.0        \n",
       " actor_3_facebook_likes actor_1_facebook_likes     gross          \n",
       " Min.   :    0.0        Min.   :    0.0        Min.   :      703  \n",
       " 1st Qu.:  120.0        1st Qu.:  623.8        1st Qu.:  9158619  \n",
       " Median :  397.5        Median :  982.0        Median : 38108330  \n",
       " Mean   :  602.2        Mean   : 5950.9        Mean   : 46927291  \n",
       " 3rd Qu.:  642.0        3rd Qu.:11000.0        3rd Qu.: 47159944  \n",
       " Max.   :19000.0        Max.   :49000.0        Max.   :658672302  \n",
       " num_voted_users  cast_total_facebook_likes facenumber_in_poster\n",
       " Min.   :     5   Min.   :    0             Min.   : 0.000      \n",
       " 1st Qu.:  7110   1st Qu.: 1466             1st Qu.: 0.000      \n",
       " Median : 31625   Median : 3142             Median : 1.000      \n",
       " Mean   : 76398   Mean   : 9103             Mean   : 1.394      \n",
       " 3rd Qu.: 87767   3rd Qu.:13884             3rd Qu.: 2.000      \n",
       " Max.   :955174   Max.   :77823             Max.   :31.000      \n",
       " num_user_for_reviews     budget            title_year   actor_2_facebook_likes\n",
       " Min.   :   1.0       Min.   :     3250   Min.   :1916   Min.   :    0.0       \n",
       " 1st Qu.:  61.0       1st Qu.:  6500000   1st Qu.:1999   1st Qu.:  301.5       \n",
       " Median : 156.0       Median : 22000000   Median :2005   Median :  605.0       \n",
       " Mean   : 257.5       Mean   : 31645256   Mean   :2002   Mean   : 1720.3       \n",
       " 3rd Qu.: 315.2       3rd Qu.: 37000000   3rd Qu.:2010   3rd Qu.:  936.5       \n",
       " Max.   :3597.0       Max.   :260000000   Max.   :2016   Max.   :29000.0       \n",
       "   imdb_score     aspect_ratio    movie_facebook_likes\n",
       " Min.   :1.900   Min.   : 1.330   Min.   :     0      \n",
       " 1st Qu.:5.800   1st Qu.: 1.850   1st Qu.:     0      \n",
       " Median :6.500   Median : 2.289   Median :    65      \n",
       " Mean   :6.426   Mean   : 2.289   Mean   :  6947      \n",
       " 3rd Qu.:7.200   3rd Qu.: 2.350   3rd Qu.:  1000      \n",
       " Max.   :8.900   Max.   :16.000   Max.   :199000      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_preprocessed<-data.frame(apply(data_preprocessed,2,replace_na_with_mean_value))\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable (Y) is the `imdb_score`, and all other variables (X) are considered as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_critic_for_reviews'</li><li>'duration'</li><li>'director_facebook_likes'</li><li>'actor_3_facebook_likes'</li><li>'actor_1_facebook_likes'</li><li>'gross'</li><li>'num_voted_users'</li><li>'cast_total_facebook_likes'</li><li>'facenumber_in_poster'</li><li>'num_user_for_reviews'</li><li>'budget'</li><li>'title_year'</li><li>'actor_2_facebook_likes'</li><li>'imdb_score'</li><li>'aspect_ratio'</li><li>'movie_facebook_likes'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_critic\\_for\\_reviews'\n",
       "\\item 'duration'\n",
       "\\item 'director\\_facebook\\_likes'\n",
       "\\item 'actor\\_3\\_facebook\\_likes'\n",
       "\\item 'actor\\_1\\_facebook\\_likes'\n",
       "\\item 'gross'\n",
       "\\item 'num\\_voted\\_users'\n",
       "\\item 'cast\\_total\\_facebook\\_likes'\n",
       "\\item 'facenumber\\_in\\_poster'\n",
       "\\item 'num\\_user\\_for\\_reviews'\n",
       "\\item 'budget'\n",
       "\\item 'title\\_year'\n",
       "\\item 'actor\\_2\\_facebook\\_likes'\n",
       "\\item 'imdb\\_score'\n",
       "\\item 'aspect\\_ratio'\n",
       "\\item 'movie\\_facebook\\_likes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_critic_for_reviews'\n",
       "2. 'duration'\n",
       "3. 'director_facebook_likes'\n",
       "4. 'actor_3_facebook_likes'\n",
       "5. 'actor_1_facebook_likes'\n",
       "6. 'gross'\n",
       "7. 'num_voted_users'\n",
       "8. 'cast_total_facebook_likes'\n",
       "9. 'facenumber_in_poster'\n",
       "10. 'num_user_for_reviews'\n",
       "11. 'budget'\n",
       "12. 'title_year'\n",
       "13. 'actor_2_facebook_likes'\n",
       "14. 'imdb_score'\n",
       "15. 'aspect_ratio'\n",
       "16. 'movie_facebook_likes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_critic_for_reviews\"    \"duration\"                 \n",
       " [3] \"director_facebook_likes\"   \"actor_3_facebook_likes\"   \n",
       " [5] \"actor_1_facebook_likes\"    \"gross\"                    \n",
       " [7] \"num_voted_users\"           \"cast_total_facebook_likes\"\n",
       " [9] \"facenumber_in_poster\"      \"num_user_for_reviews\"     \n",
       "[11] \"budget\"                    \"title_year\"               \n",
       "[13] \"actor_2_facebook_likes\"    \"imdb_score\"               \n",
       "[15] \"aspect_ratio\"              \"movie_facebook_likes\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_critic_for_reviews'</li><li>'duration'</li><li>'director_facebook_likes'</li><li>'actor_3_facebook_likes'</li><li>'actor_1_facebook_likes'</li><li>'gross'</li><li>'num_voted_users'</li><li>'cast_total_facebook_likes'</li><li>'facenumber_in_poster'</li><li>'num_user_for_reviews'</li><li>'budget'</li><li>'title_year'</li><li>'actor_2_facebook_likes'</li><li>'aspect_ratio'</li><li>'movie_facebook_likes'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_critic\\_for\\_reviews'\n",
       "\\item 'duration'\n",
       "\\item 'director\\_facebook\\_likes'\n",
       "\\item 'actor\\_3\\_facebook\\_likes'\n",
       "\\item 'actor\\_1\\_facebook\\_likes'\n",
       "\\item 'gross'\n",
       "\\item 'num\\_voted\\_users'\n",
       "\\item 'cast\\_total\\_facebook\\_likes'\n",
       "\\item 'facenumber\\_in\\_poster'\n",
       "\\item 'num\\_user\\_for\\_reviews'\n",
       "\\item 'budget'\n",
       "\\item 'title\\_year'\n",
       "\\item 'actor\\_2\\_facebook\\_likes'\n",
       "\\item 'aspect\\_ratio'\n",
       "\\item 'movie\\_facebook\\_likes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_critic_for_reviews'\n",
       "2. 'duration'\n",
       "3. 'director_facebook_likes'\n",
       "4. 'actor_3_facebook_likes'\n",
       "5. 'actor_1_facebook_likes'\n",
       "6. 'gross'\n",
       "7. 'num_voted_users'\n",
       "8. 'cast_total_facebook_likes'\n",
       "9. 'facenumber_in_poster'\n",
       "10. 'num_user_for_reviews'\n",
       "11. 'budget'\n",
       "12. 'title_year'\n",
       "13. 'actor_2_facebook_likes'\n",
       "14. 'aspect_ratio'\n",
       "15. 'movie_facebook_likes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_critic_for_reviews\"    \"duration\"                 \n",
       " [3] \"director_facebook_likes\"   \"actor_3_facebook_likes\"   \n",
       " [5] \"actor_1_facebook_likes\"    \"gross\"                    \n",
       " [7] \"num_voted_users\"           \"cast_total_facebook_likes\"\n",
       " [9] \"facenumber_in_poster\"      \"num_user_for_reviews\"     \n",
       "[11] \"budget\"                    \"title_year\"               \n",
       "[13] \"actor_2_facebook_likes\"    \"aspect_ratio\"             \n",
       "[15] \"movie_facebook_likes\"     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setdiff(colnames(data_preprocessed),\"imdb_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=20, repr.plot.height=10)\n",
    "set.seed(3)\n",
    "\n",
    "X<-data_preprocessed[,setdiff(colnames(data_preprocessed),\"imdb_score\")]\n",
    "Y<-data_preprocessed[,\"imdb_score\"]\n",
    "\n",
    "N<-nrow(X)    #Number of examples\n",
    "n<-ncol(X)    #Number of input variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the `imdb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACWAAAASwCAMAAABIeoGzAAAAM1BMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"Histogram of Y\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 600,
       "width": 1200
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "6.4255"
      ],
      "text/latex": [
       "6.4255"
      ],
      "text/markdown": [
       "6.4255"
      ],
      "text/plain": [
       "[1] 6.4255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.2469466966967"
      ],
      "text/latex": [
       "1.2469466966967"
      ],
      "text/markdown": [
       "1.2469466966967"
      ],
      "text/plain": [
       "[1] 1.246947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Modelling with linear and decision tree models\n",
    "\n",
    "#### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us create a linear model for predicting the IMDB score on the basis of the other variables, and compute its empricial mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Empirical error= 0.9084\"\n"
     ]
    }
   ],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "    \n",
    "model<- lm(imdb_score~.,DS) ### Fill with your code here\n",
    "        \n",
    "Y_hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<-mean((Y_hat-Y)^2) ### Fill with your code here\n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which input variables are statistically correlated with the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = imdb_score ~ ., data = DS)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-4.0647 -0.5016  0.0481  0.6020  2.7334 \n",
       "\n",
       "Coefficients:\n",
       "                            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)                4.677e+01  5.394e+00   8.670  < 2e-16 ***\n",
       "num_critic_for_reviews     2.123e-03  4.381e-04   4.845 1.47e-06 ***\n",
       "duration                   4.324e-03  1.266e-03   3.416 0.000661 ***\n",
       "director_facebook_likes   -1.463e-06  1.173e-05  -0.125 0.900836    \n",
       "actor_3_facebook_likes     9.516e-05  5.313e-05   1.791 0.073619 .  \n",
       "actor_1_facebook_likes     9.347e-05  3.055e-05   3.060 0.002275 ** \n",
       "gross                     -9.636e-10  7.420e-10  -1.299 0.194388    \n",
       "num_voted_users            3.512e-06  5.086e-07   6.905 8.98e-12 ***\n",
       "cast_total_facebook_likes -9.161e-05  2.964e-05  -3.091 0.002050 ** \n",
       "facenumber_in_poster      -1.959e-02  1.446e-02  -1.354 0.175903    \n",
       "num_user_for_reviews      -3.360e-04  1.503e-04  -2.235 0.025667 *  \n",
       "budget                    -3.423e-09  1.110e-09  -3.084 0.002103 ** \n",
       "title_year                -2.056e-02  2.688e-03  -7.647 4.88e-14 ***\n",
       "actor_2_facebook_likes     1.080e-04  3.176e-05   3.400 0.000701 ***\n",
       "aspect_ratio               4.232e-02  1.943e-02   2.178 0.029645 *  \n",
       "movie_facebook_likes       1.519e-06  2.396e-06   0.634 0.526130    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.9608 on 984 degrees of freedom\n",
       "Multiple R-squared:  0.2708,\tAdjusted R-squared:  0.2597 \n",
       "F-statistic: 24.36 on 15 and 984 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the validation error with a 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CV error= 0.9482  ; std dev= 0.1812\"\n"
     ]
    }
   ],
   "source": [
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-numeric(CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "     idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "     X_ts<-X[idx_ts,]  \n",
    "     Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "     idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "     X_tr<-X[idx_tr,]\n",
    "     Y_tr<-Y[idx_tr]                          \n",
    "     \n",
    "     DS<-cbind(X_tr,imdb_score=Y_tr)\n",
    "    \n",
    "     # Model fit (using lm function)\n",
    "     model<- lm(imdb_score~.,DS)\n",
    "     \n",
    "     # Model prediction \n",
    "     Y_hat_ts<- predict(model,X_ts)\n",
    "     \n",
    "     # Cross validation error = Mean Squared Error\n",
    "     CV_err[i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV_err),digits=4), \" ; std dev=\",round(sd(CV_err),digits=4)))\n",
    "\n",
    "CV_err_lm_single_model <- CV_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify the previous code to compute the empirical error using a decision tree model. Use the rpart package (see `?rpart` for help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'rpart' was built under R version 4.0.4\"\n"
     ]
    }
   ],
   "source": [
    "library(rpart)       ### Run install.packages(\"rpart\") to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Empirical error= 0.6665\"\n"
     ]
    }
   ],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "\n",
    "model<- rpart(imdb_score~.,DS) ### Fill with you code here\n",
    "        \n",
    "Y_hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<-mean((Y_hat-Y)^2) \n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the resulting tree using the `prp` function from the library `rpart.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'rpart.plot' was built under R version 4.0.5\"\n"
     ]
    }
   ],
   "source": [
    "library(rpart.plot)  ### Run install.packages(\"rpart.plot\") to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACWAAAASwCAMAAABIeoGzAAAAMFBMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD////QFLu4AAAACXBIWXMAABJ0AAAS\ndAHeZh94AAAgAElEQVR4nOzdiVrqOhQG0BQ4OADy/m97KIOAohZI251mre/eAzKZOb8Fa9oC\nAJBVGrsAAABTI2ABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBk\nJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEA\nZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmAB\nAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZg\nAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQm\nYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBk\nJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAEA\nZCZgAQBkJmABAGQmYAEAZCZgAQBkJmABAGQmYAGUIfVp7MrlsV78du9rk+ari8vvD5ilZtlL\nwZ6gh0ulyQEK0PcOOY0d+HYljrHrZZ8z1p+X3574ur/j14w2tIzdMo0eLon2BohviLU60H6Q\n0mqW5ptj8Gn/Sem1mW1e0mzz+aBV+rf7919a7a7O0mx1PNiz3b4fvjraLI7JIqXNdr17zuny\n8oH7hyx2L7UOFUMylyVS1SqguQHiG2StjrMhHN7Uml8FrPaG3f+z86Nm+zubNmq1VseAtbo8\nQvWxTGm5Pr7oepefms/Lywd+xqpD8goie4fE6eEaaG2A8IZZquNsCO0bdatDrtqeAtbbx+7/\nzeUBppf0tn1LL9vtPC23y888Nt8HqENOWqbm9ePz4YcAdrr8fODFp5RmlwFudAJW0bQ2QHj1\nBayPU67anq983nD0sctU89MjLx/eavYP2QWs5SlgbV+atGzS+fL0wMuPga8cwSITrQ0QXn0B\na9shYG0X6b09brW/8eNLwDo+7uItwsMrz86XFw88fAar2X75BiMTsIqmtQHCqzhgrbbLHwPW\n+y4evW9vvUV44eP0IffF7vbl7pGny8sH7h/yb3fj+/HQVwgCVtG0NkB41Qas+ekg082AtW0O\ncejz0+pNSv+OX12cbeHyNA3N5vPy8oH7l13vv34dqI4dCFhF09oA4VUbsDbzNHv/OWDtD0Rt\nP0/TsF01bV56++F8octd/NpcXH57YPsyb/3U6CECVtG0NkB4tQUs9gSsomltgPAErCoJWEXT\n2gDhCVgX6vnjen9VMW2PvzWZ6wXJSWsDhCdgVenPgLVPWKl7z+nhIWltgPA6LtXp8P/FqZ36\n+C4M5e8jWKeDWJlekJy0NkB43QPWl//6+C4MRcAqmtYGCO+egHVx4qh+vgtD+aND7k/SenhI\nWhsgvM4B63K3vTti2RCC6RSwfMg9Kq0NEF7nt4CuDmoIWIVzmoaiaW2A8O76jM3pM+4+5F46\nAatoWhsgvGE+xGxDCEbAKprWBgiv21L97Lk3bQjBCFhF09oA4TnRaJUErKJpbYDwBKwqCVhF\n09oA4U0xYJX9xwQH+VuIAlbRtDZAfIOs1UNuCGXHq73+M5aAVTStDRDfEGv1gPvBBOLVXt8Z\nK/OrT6TVS6G5AQrQ+1Y+YOaZSrza67cyGbtlyB6mpb0BypD6NGQ1hvteg+i59crrYQ40OQCD\nmeZGL7/wnTEBwEAmnENkLL4wIAAYxsR3HBGLS4YDAEOoIH84jMWZsQBA/2qJHjIWRwYCAH2r\nKnXIWLSMAgD6VV/gqK/GfGMMANCnOsOGw1jVMwAA6E/FOUPGqpveB6AvtUcMGatiuh6AfkgX\nW41QLx0PQC9sMAcOY9VJrwPQA6nigoxVIV0OQHYCxVdapDY6HIDMhIlbHMaqi94GICs54kcy\nVkV0NQAZiRC/k7FqoZ8ByEZ66EAjVUEvA5CJ5NCRw1gV0MUA5GFHuYOMNXX6F4AcBIZ7yViT\npnMBeJ6s8BDNNl26FoBnyQkPcxhrqvQrAM8REZ4jY02STgXgGdJBBjLW9OhRAB4nGOSiJSdG\nfwLwKKEgJ4exJkVnAvAYeSA7GWs69CQAD7GB9ELGmgjdCMADxID+aNsp0IkA3E0E6JfDWOXT\ngwDcye4/ABmrcLoPgLvY+IeipUum8wC4g01/SA5jlUvPAdCZ/X5wMlahdBsAHdnqxyFjlUif\nAdCNHWM8IlZx9BgAXdjix+UwVmF0FwB/s7sHIGOVRF8B8BcbexQyVjF0FAC/s6eHojvKoJsA\n+I39PByHsUqgjwD4ma08JhkrPB0EwE/s4oHJWLHpHQBus4FHp4cC0zcA3GSDKIDDWGHpGABu\nsHGXQsaKSa8A8I09uyi6KyB9AsAX9uviOIwVjg4B4IqtukwyVix6A4ALdumCyViB6AoAPtmg\nS6cHo9ARABzZnKfAYawY9AIAB3aEqZCxAtAFALTsyZMiY41N+wMgXk2RPh2V1gfAVjxNDmON\nSNMD1M4uPGEy1li0O0DdbMBTJ2ONQqMD1MzeWwXdPDxNDlAv+241HMYamvYGqJUtty4y1qA0\nNkClbAD1kbGGo6UBqmSnrZSOH4h2BqiQXbZiDmMNQiMDVMcGWzsZq39aGKAy9la2hkHvtC9A\nVeyrMAQTDaAi4hUMw1QDqIZ4BUMx2QAqIV7BcEw3gDpY72FAJhxADRy+gkGZcQDTJ17BwMw5\ngKkTr2BwZh3AtIlXMALzDmDKxCsYhZkHMF3iFYzE3AOYKvEKRmP2AUyUBR7GY/4BTJLDV3T2\nw2C5ffN68csrvc5Ss9xdro6X32wWKb3cXcASmYAAEyRecYe7Atbp1sX6+32vqbXYrvaXy+/P\n2zTtHVUkLFMQYHLEK+6S0nvTvG2PI2f/z1vTvB+vzDb7K++zNFu196bD+NoFqc3h8vOm7SKt\ntuvd9UV6bUPW+Vmnl13uUtc6/XYMbDJMQoCJEa+40yEivV8ErPdTamqPRTWnKymtzwFrvUxp\n+XEdsPa3p3+7gNW+zuz8rOPLbmf1DM56agpQBfGKu7Vv2r2k+UXAmu9vOV5ZHq6s99npYoR9\nvDTp2wetZm2uai3bxHZ6Vjpplqmp4h1CAQtgSsQrHpDSx/ajHTufAevils8r+3z0PWB9PYK1\nalNYm69et+dnpStVJCxTEWAyxCse0g6crwFrezNgpfMou/UW4aI5Pn+7SG+HV774zNbun2Z/\nRKuKcVpFJQFqUMe2RQ9Sej29Rbg6vSG4PF25eIvw+ODT5eLj6wv92z3tvT3MNW/fH9xePOv4\nvH+7rzd1jNQqKglQAes5jzocZlq1eejis+37K+2JF2bnWxbtQajDe4C3TtOw3j/otY1kl6+z\nOHyTzwd4ixCAQtRxUIB+pNSelWF3ZTNPs8PZGdrzNlyfpuHtdA7R5pfTLKxmafa2D2HHdwbf\nvpxxdDVPzWufdQnDjAQon3hFT1LabFftm37cyZwEKJ14RW8WN87JThdmJUDZxCv69C/98FcF\n+Z15CVAy8QpCMjMByiVeQVDmJkCpxCsIy+wEKJQFHOIyPwGK5PAVRGaCAhRIvILYTFGA4ohX\nEJ1JClAY8QriM00BiiJeQQlMVICCiFdQBlMVoBjiFZTCZAUohHjFOB4eeFWP2KorD1AQ6zXj\neGLk1Txoa647QDkcvmIkT428iodtxVUHKIZ4xWieG3v1jtx6aw5QCvGK8Tw7+KodvNVWHKAQ\n4hVjenr41Tp+a603QBnEK0aVYfxVOoQrrTZAEcQrRpZjBNY5iuusNUAJxCvGlmcIVjmQq6w0\nQAks0Iwu0yCscSzXWGeAAjh8xfiyDcIKR3OFVQYAusgXEuqLG/XVGADoImdGqC5vVFdhAKCL\nvBGhtsBRW30BgE4yR4TKEkdl1QUAOsmeEOqKHHXVFgDoJn9CqCpzVFVZAKCbPgJCTaGjproC\nAB31EhAqSh0VVRUA6KinfFBP7KinpgBAV33lg2pyRzUVBQC66i8e1BI8aqknANBZj/GgkuRR\nSTUBgM56TQd1RI86agkAdNZzOKgie1RRSYCepJ8X0fXi9/uv/Ns/7n2WZu+7y2WTmmWG0sGD\n+g4HNYSPGuoI0JdfAlSHbLXPYDubxf7B69Rab5f7SwmL0fSfDSpIHxVUEaAXb03z3gajfTg6\nXNk0s31amm+2+5B0uG81S7PV/jG7a7u7jo6xqr1jvr/2bxeqlunftg1Z667HviC/AQbf9Mf3\n9GsI0Iv3dMhQlwEr7eLRvL2YXQSs1f7q6nD/Lnwdnv6xTGm5PlxfHF6j2b9Qs53tA9ZspHrB\nINFg8vlj8hUE6Mc8vWxfvgSs5fajvWtzdfN8f2Bq3n6xaNPW/tnL1Lx+nF/s88HtP5tZG9E2\n374jDGOYaDD1ADL1+gH0JKWP7ceXgLWPTOuX+ZebL+8/B6zlTwFr3ewCVrMeukJwMFQymHgC\nmXj1APrSxqGvAau9/T29bL7dfP3A1uVbhFtvERLIYMlg2h80nHTlAPpzeOdvn5tWpyvt7U3a\nrH56i3B7uad8LM7XfcidMIYceVMe5VOuG0CPVqcPuc+vPu2+bT9A1R6LatI+K50euP4WsM6n\naTjeenqg0zQwpkGDwYRTyISrBtCr96Z5a4PRZp5m5/M1tB9RX2x28WjVpMXX0zRsf3pXJF2d\naPR1lpqXoaoBVwbOBdONIdOtGQBwp8FjwWRzyGQrBgDca/hYMNUgMtV6AQD3GiMVTDSJTLRa\nAMDdRkkF04wi06wVAHC3kULBJLPIJCsFANxvrFAwxTAyxToBAPcbLxNMMI1MsEoAwANGzATT\niyPTqxEA8IBRI8Hk8sjkKgQAPGLcSDC1QDK1+gAAjxg7EYz9/TObWHUAgEeMHwjGL0FO06oN\nAPCQAIEgQBHymVRlAHo3+qqZ0uhFYIpCDKsQhchkSnUB6FuMcCNjkV+MMRWjFFlMqCoAPQuU\na2Qs8ooynqKU43nTqQlAz4ItmDIWGYUZTGEK8qzJVASgXxHjjIxFJoEGUqCiPGUq9QDoV9TV\nUsYih0ijKFJZnjCRagD0KnSKkbF4VqwRFKs0j5pGLQD6FD/AxC8hoQUbP8GK85hJVAKgT0Us\nlA5j8bhwYydcgR4whToA9Kic4CJj8ZiA4yZgke41gSoA9KisVVLG4gERB03EMt2n/BoA9KfA\nvCJjcaeYAyZmqe5QfAUAelNqVJGxuEfQ0RK0WJ2VXn6A3pS8QMpYdBV2pIQtWDeFFx+gL8Un\nFBmLTuIOk7gl66Ls0gP0ZRKro4zFnyIPkchl+1PRhQfoyXSCiYzF70KPj9CF+0PJZQfox8Qy\niYzFz4KPjeDF+03BRQfoxwQXRhmLH0QfGNHL97NySw7Qi6lGkanWi6fEHxXxS/iDYgsO0IsJ\nr4oOY/FVCSOihDLeUmq5Afow9QgiY3GliOFQRCG/K7TYAD2oIn3IWHwqZCgUUswvyiw1QA+q\nWRBlLA5KGQellPNKkYUGyE/ooDaxh3z6ydgF66iUcgL0y2pIdYIO+r9yVCE5K3wBAQYQf7WG\n3CIO+juSU/SQFbpwAIOIvU5DP6IN+wcSU+SQFbZgAEOxEFKjWOP+8aQUNWIFLRbAUKIuz9Cv\nSAP/uVkY8zBWxDIBDMcqSJ0CjfwM+ShgxIpXIoDhBFyWYQhxRn6mSRhuLkcrD8Bwwi3JMJQo\nYz/jJAw2n2OVBmBAFkCqFWXw5y1HqIgVqSwAAwq1FsOwgoz+7MUIUq9WoKIADMjqR8WCDP/8\nxQhSsVagogAMxuErqhZk/PdQjCA120YqCcBQxKsvfmiQ2zevF7+80ussNcuLy282i5Re7i4g\neQWZAH0UI0jVtpFKAjAQC99XdwWs062L9ff7Xvd/hXfxefnteZumvUPCGlmMKdBPKWLUbRuo\nIADDcPjqu5Tem+Zte2yc/T9vTfN+vDLb7K+8z9Jsdfjrb+nwpMXmcPl503aRVtv17vrp8vNZ\np5ddpuXujt+OgdG/IFPg72JcDK1t1xO2B6lcoIIADMKqd8NhH3u/CFjvp61ttfu3OV1JaX0O\nWOtlSsuP64C1vz39O1+ennV82e1M+wcQoxO6liJdXHZ4TozKbQMVBGAADl/d1L5p95LmFwFr\nvr/leGV5uLI+ZKZzG368NOnbB61maXZxeXpWOmmWqfEO4biCTIKOxUhfLnO9bu+ilAOgf+LV\nD1L62H60rfMZsC5u+byyz0ffA9bXI1ir4xGs1SGNHZ6VrkhYY4oyCwQsgImw4P2kjUdfA9b2\nZsBK54B16y3CRXN4/uny8s79v83+iJaeGFOU1u9WjvMnsDp+Bquw+gEUz67+s5ReT28Rrk5v\nCC5PVy7eIjw++HS5+Pj6Qv92T3tPzefl+VnH5/3bfb3RFWMK0/j3BqyOn8EKU8Eo5QDolT39\nN4fDTKs2D118tn1/pT3hwux8y6I9CHV4D/DWaRrW+we9fl6en3XsgrW3CMcWZybcdzwqdXxK\nmPqFKQhAj6x1v0qpPSvD7spmnmaHszO05224Pk3D2/Hcoavml9MsrGZp9nZx+fmszwfMU/Pa\nX034S6CpcN/hKAELIByHrx6X0ma7at/sYxoCzQUBC6BsFronLPbv6d38qzcUKNRk6B6XDr98\n0eUnpTgVjFMSgF44fPWcf+mHvypIiWLNhvylCVS/QEUByE+8grNo0yF7eQJVMFBRALKzxsGF\ncBMic4Ei1S9SWQDycvgKLgWcEDmLFGvChyoMQE4WOLgUckbkS0XBqhesOAC5xPppFsYXdErk\nKVa4CR+tPABZhFttYWxh50SG2RpwwscrEcDzrG3wVeBZ8Vw+6vhXoAcWsUwAzwm53MK4Ys+K\nx0NS1OketFgAj7OwwXfh50W3U7U/+5TBhC0YwGPiLrgwojLmxR2JKXK4aoUuHMC9Yi+5MJpy\nZkbqZuxi/iV8AQHuYE3rw4OtqjMi0RtD0+LAdMT/obZID7eq7ghEZwxNiwOTYUHrxRPNqkfC\n0BWD0+TARDh81RMBawL0xPC0OTAJ4lVfnjsDZK5S8BwdMTxtDkyBtawvT7asjglBN4xAowPl\nc/iqP882ra6JQC+MQKMDxbOQ9efpttU5AeiEMWh1oHAOX/UoQ9vqnvHpgzFodaBo4lWvcrSu\nHhqbHhiFZgdKZg3rVZ7m1Ukj0wGj0OwA3JZrh7DTUCHDHoDbBCx4mGEPwE35NghbDfUx6gG4\nJef+YK+hOgY9ALdk3R9sNtTGmAfghszbg92GyhjyANwgYMEzDHkAvsu+O9huqIsRD8A3PWwO\n9huqYsAD8E0fm4MNh5oY7wB81c/eYMehIoY7AF/0tDXYcaiI4Q7AF31tDbYc6mG0A3Ctv53B\nntOj9eK3e1ez1Cx3l6/Hy+323+3eOD+ApxjswFDSzwvOfmv45f4bNouUXvbPaj1ZNC712Zp6\nqj+3p8Exdq3282S5fd1fLg4T6NYLfD6AJxnrwFB+iUG/J6TF+vttm6bdBl62awEru15bU1f9\nKaXVLM03x2nR/pPSazPbvKTZ5vNBq/Rv2x6EWu2PTc1Wxx81ttv3w1dHnzFqkV7bkLW7XLWT\nZvfw+fGe8xP2N3w+gCdpQ2AIb03zftgptqctY9PM9sv/bic5bA37+46bxXmT2V9fbA6X5zC1\n3P0wvt79nP222zfIqt99wa7zp8Mwn1/NlvaG3f+z86Nm+zub07Gp1XEWHb46/kjysUxpebi+\n2D/88Px1G84Wxx9rLp7wGav2D+BJhjowgPdTNLraMv5t2z1jt+ifA9ZpszhvMjvrdpv4uA5Y\ns+PqtUyz1MhYGfW9Ldh2/tK+Qbf6MlvePnb/by4PLL2kt92PFy/b3SRa7qbBKY/Nd1nplI+W\nu6nxcfHCy/TeXsyOOevwaqcnpPP0ml0GOR5lpAMDmO82gpcvW8Zyu1/7N1c3X2wWx01m7+Ol\nSdefu03Nbvd4aX8wb0lY+fS+Ldh3/pDSx2mSbM9XPm84+thNk/npkZcPbzX7h+ymyPIiYC1P\n8+Tw9uLx1U5PuAhYpwfwFAMdGEC7ZXx82TL2K//6Zf5tJznf/yVgXR7BOlx92S6a9e7neD9w\nZzPArmDj+d2t2fA9YO1+tnjfH+Jtb/z4ErCOj7t4i7B9/Fv7b7M9R6vt9RMOn8E6P4CnaENg\nAF/3gNMK/p5eNt9uvn7g9vZbhM3+jY10fnnyELBGdzEbVtvljwGrfd+9fcvv+1uEFz4+f1dw\nfnh/8N/u0e+HI1zntwgvv/HFA3iKcQ4M4LAHfN0y2pi0uf6wyfVm8Xm0avHx9RX/7baFNpvN\ndi/47ghWNoNsCnaeX13MhouPLn4LWLvZs49Bn59Sb9qPNa6+nmXheJqG5fG11uf31C8/5L74\nvOHiATzFMAcGsDrtFFdbRvtp2pSadNwazh9yX18HrFunaVgf3yJ8PX0qnhwG2hNsPb/5HPub\neZq9/xywlsfPJZ5+83bVtDnp7fZ5QpvTzGsf/Xb+Pt+fcH4ATzHKgSG8N83bty1j9+UsLTa7\nbWK/NXw5TcP2635ybTU//Pbga3N52h+eM9SeYO9h8gxyAI6G2xJsPkydMQ7AwYA7gs3nQZdn\nUyA0fQTAwZA7gt2HiTPEAdgbdkOw/TBtRjgAraH3A/sPk2aAA9AafD+wATFlxjcA2zG2AxsQ\nU2Z8AzDObmAHYsIMbwBG2g1sQUyX0Q3AWJuBPYjJMrgBGG0vsAkxVcY2AAIWZGZsA1RvxK3A\nLsREGdrA0Hpcd/yNtseM2Wp67EE5Gs586ZG2BQbW87IjY91v3BbTXw/J1GymS2+0LDCsAVYd\nGes+Y7fW2N+/SPkazXTpiWYFBjXQomPTuMPYTTX29y9R3jYzW/qgUYEhDbjmyFgdjd9M45eg\nNNlbzGTJT5MCAxp4yZGxOojQRBHKUJI+2stcyU2DAsMZYcWRsf4Son1CFKIYPbWWqZKX5gQG\nM9afY7HQ/SJI4wQpRhH6aytTJSeNCQxlvPXGYawfRWmYKOUoQK9NZarkoyWBgYx8siUbx01h\nWiVMQaLrvaHMlEy0IzCM8VcbGeu7QC0SqCiRDdFMJkoWWhEYRIzFRsa6Fqo1QhWmcuZJBtoQ\nGEKctUbGuhCqKUIVJqrBGsk0eZoWBAYQa6mRsY6CNUOw4kQ0ZBOZJk/SfED/4q00No9twG4J\nV6Bohm4gs+QZGg/oXcyFRsaKV/94JQpllBP1Dv89p0LTAX2Lu87UnbEi1j1imcIYp3GqniNP\n0XBA1SrOWBErHrFMUYzWNvVOkedoNqBn4ZeZSjNWzErHLFUEY7ZMnTPkWRoN6FcRq0yFGStq\nhaOWa2wjt0uFM+RpWgzoVTGLTG07SNjahi3YqAK0SmUT5HnaC+hTUWtMTRkrcE0DF200Mdqk\novmRg9YCelTcElNLxopcy8hlG0mYJqlkeuShrYD+FLnCVJGxQlcxdOHGEKlBapgdmWgpoDfF\nLjCTz1jBqxe8eJWb+uTIRjsBfSlofUndjF3MXCZTkTqM/wuENU2OfDQJ0JNSlpc7Noep7COT\nqEQ1xj0BVnWTIx/NAfSjiNXlgU1hAvtI6eWvy4gncK9xcmSkKYBelLC4PLwZlL2LFF346ozV\nW5VOjpw0BNCHAtaWpzaCkn9SL7fkFRqps6qdHDlpBaAH4ZeWDHtAqbtIocWu0yidVfHkyEob\nAPlFX1kyLf9F7iIllrlaY3RWzZMjLy0AZBd8Ycm49Be4i5RX4nqN0Fd1T468aq8/kF/wdSVv\n8UrbRQorbtXGyFd5X63u0VZ37YEeBF9WshcveH2/KKu0VSs+X/XxgiWpuvJAD4KvKvmLF7zC\n14oqbN2mkK/qHm9VVx7IL/qi0kP5olf5QkFFrd0on28v4iWLUXPdgfyiryl9lC96nS8UVNTK\nTSRfVT3iaq47kF30JaWf8kWv9adiCsoIKp8c+VVcdSC78CvK3wVM6frvqXWpUvhqH0Ur5y+/\nZLZe/H7/lX/Hx3007ZXNIqWXp8s2spgHsK4mR8e/Oxht0A2o4qoDuYVfULoW8Py4bnt8+Iof\nRCvmL43bod33GWx7CFSHa/P2yqZpd/7CE1bMfHX1uNT1OdFG3XDqrTmQW/z1pGMJL/JVt6fE\nr3krVCnfmua9zUP7cHS4smlm+7Q03xwOlRzuW83SbLV/zO7a7q6jc6xK8+O111l7ZZmW23Va\nDF+jjMb5Azn3PUzA+lO9NQcyK2A5uTdgpa5PKaDuscr4fnq36SJgpfSvPQiV0uwiYK32V1en\nt6fmh6d/LFNarg/XF8fDXeu0bq/MQtXzIePU4O6fPro+p/wOeVC1FQcyK2E1uTctCVh9maeX\n7cuXgLXcfrR3ba5unu9uXra5KqVFm7b2z16m5vXj/GKHW2cvh9dpdvcW/Q7hSB1190jv+jeh\nQw28IVVbcSCvIhaTOzeE1PUpJVQ+VhlT+th+fAlY+8i0fpl/ufny/nPAWn4NWMv5+UhY0Z/B\nGqujHklL3iL8Tb01B3IqZC25Ky51/pRJCbUPVsQ2Cn0NWO3t7+ll8+3m6we2Lt8i/Lzr8L5i\nk9bbdcF/BG+8kj8w1AWs39RbcyCjUpaSuzaE05ad5VXHFqyMh3f+9rlpdbrS3t6kzeqntwi3\nl79c+LFIFx21PffWv13A2pQbsEYs+H1pqeuPH8X2xPMqrjqQTTEryf0/cU/kZ/RoRVydwuv8\n6tPu29nuens2q6b9xPv5Q+7rbwHrfJqGi1vbK+ui3yIcs58ErMwqrjqQS0ELSfcd4friydcc\nXbgyvjfN2/60VfM0O5+vYbuZpcUmLberJi2+nqZhex2wzq4C1nY1T83rIHXIb9xuum9yTOfo\nbl9qrjuQR1HrSP7CllD9EsrI6N1U5+ToTdWVB3IobBnJXtwC6l9AEYnQTTVOjv5UXXkggycO\nfMMAACAASURBVOJWkcwFLqH+JZSRCL1U4eToT921B55W4CKS81fMivh1tRLKSAzVTY4eVV59\n4EllriHZSl1E9YsoJFG6qa7J0afqGwB4RqlLSJ6frQv5Cb2MUtYuTi9VNTn6pAWAxxW8gjy/\n/peygxRSzMqF6qV6JkevtAHwsLIXkKf2gK5/6HZ8pZSzbtF6qZLJ0S+tADyq+PXj4X2gpA2k\noKLWK2AnVTE5+qUhgAdNYfnodjbqZ58yppLKWq2YnTT9ydEzTQE8ZjKrxx2bQnn7R2HFrVPg\nTpr05Oib5gAeMq3FI3UzdjHvV2CRqxO9jyY7OfqmSYBHWDuKUFw3PVTg4mp5pezS8zM9CzzA\n0lGE8rrpsRKXV8+zksvOr3QtcD8rRxmK66eHf3MtaymGVG7J+Yu+Be5m4ShDcf30eIGLq+pR\nqeWmA50L3Mu6UYjiOuqJAhdXVybPmATuZNkoRHEd9VSBi6ttq8hC05HeBe5j1ShEeR31XInL\nq2+JRaY73QvcxaJRiuJ66tkCV1dhYtO/wD2sGaUorqeKK/CzqqtwbXQwwASVt7g/X+Ky6lxW\nabmfHgbuYMkoRXE9laPAJVW6pLLyEF0MMA1l/5W4LKWMXdWyO4h76VeAov29TZewkWcqW8Qq\n3tFBEYvPo/QmQKHu3pMDb+K5ShWqdve3d+Ae4l76EaBEj+/DETfwfEWKU7nH2zliD3E3vQhQ\nnue24HAHSXIWJ0jVnu2hXOVgNPoQoDQZtt9YO3jWwkSo2fPNG6uDeIAeBChMnoU70PKfuSij\n1yxPOBKxCqf/AIqSbd+Ns4HnLsjIFcv27cN0EI/QfQAlmeLHlQp4xTu+d8ZvHicDcz+dB1CQ\nvIt2iC0gRCGymdrbnTxM3wGUY2Jvpu31UYbR6pX9G0foIR6i6wCKMa030/oswUj16uHbjt9D\nPEbPAZRiUsd6ei7AKPXq5ZuO3kM8RscBv/tojuvEz38tbbNI6WXQQtVpUsd6ev/2I9RrSlmR\np+k34GixvnnzPF0FrOXVnfv7Nk17h4TVuy4L9lUE7rTCTzVgjVCxezuo4xn1bdRl0m8wcW/N\nbNMu4yltmtl2u5ql2Wp382aXmxab8+W2fcThyvWRqtfZ5Sbw2rT/vh9f5BiwlrvUtU6LwapU\nrQ4Ldrp8WAnbd5/fffCa3dlBV5313MsSkH6DaVvtolJzCFgp/dt/mdIuHM3ay/n5cme9TGn5\n8SVgrdP6Ypv+SK/H10xpf7xrf9/MQjKIjtv3xRfdOmbUk0YV/OqPfLv0w/WnX5h4dBtM2zy9\nbJeHgLXcfuy+XO6+nLdffuzvP13ufbw0X94C3M5eLo+DLNPhNde74PXvlMR2CW6ZGu8Q9u7e\ngNV1hZ9uwBq4agIWl3QbTFsboD4OAetjezzi1P7zktK8PRp1utw7BKzLI1jL+dUbTc2/w2vu\nU9U5YCWfwRpCp/37/s9gjbkP9P6tB63bnR2Uun4Gy05dJt0G03YRsA5fbg9fbl8Xs/3Hpk6X\nt98ivP481nt6+3Lj/t9mf0TLatK3Lvv39cd6wm/f/X/rISt3Zwd96aznXph4dBtM28VbhIcv\nj28RtlK6ukxp8fH16dcB69/hg1fztD7ff7x5I2D1rus7UOUErImNmTs76EtnPffCxKPbYNpe\nd/Fodg5Yn59Pn7eXi/Pl9sfTNJzfVjx9mv3wIovP+9beIhzG3wv2IwFr4vkq1iGshwKWjbpM\n+g0m7nyahv2Xp9M0fPw7nJXhdPmLc8A6HaV6m6Xm8sPwq3lqXm88k7wErLjfpeO3ErAqot9g\n2lLabFepGbsY5NDpMz7pYt+OHbCG+sbDVfDODvrhDyM88rIEpN9g2hY3Tr9OqfpYsad+AGvI\nb9TPd7JPF0rHwcT9S9dv51Gy/Et2Bfmq8IRlmy6VngMoR+41e9KnaBjje2X/TnbpYuk6gILk\nXbQryVcFJyybdLn0HUBJcq7a1eSrQRNWxm/l7HIl03kARcm26Y66ew/+vUv8yJcdumi6D6Aw\neRbuUZf/Eb75kAkry/dy+Kpw+g+gNM9vvV3/zHBfxvjug36qPkMP5SgHI9KDAOXpeo7K3M/N\nZOzvP4DCe4jn6UOAMqUH9uEYW/dIRRj+c18PtHaMHiID/QhQsDv24zhb91jFGOWNyTtaPU4P\nkYG+BChcSr8fzPrr/qFVcfb4q2/brYPi9BA56E+AaUg/GbtgX1V0+q3rb15KB5GFfoXyTHVB\nttfUobbzQ1ApYw0KM/UMImRNXn0niKBKhhqUpJLw4VDWlI3ds2N/f2phpEE56godUtY0jd+n\n45eAKhhoUIg604aUNTkBujNAEaiAcQYlqDtlSFkTEqIjQxSCqTPMID7pYitlTUWMPoxRCqbN\nKIPgxIoLUlbp9B7VMNghMnHiBiGrXGE6LkxBmC6DDOKSI37kUFaZ4vRZnJIwVcYYBCVA/EnK\nKk2k3opUFibJEIOIBIfOpKyChOqoUIVhgowwiEdguJeUVYRgXRSsOEyNAQbBSAqPkrKCC9c5\n4QrEpBhfEImE8CwpK654/RKvREyI4QVxSAaZCFkRReySiGViKowuCEImyMuhrGhC9kbIQjEN\nBhdEIAv0Q8qKI2g/BC0WE2BswfhkgF5JWSFE7YKo5aJ4hhaMzOY/CClrZBqf2hjzMCab/qCk\nrNEEbvbARaNoRhaMx2Y/BilrDJFbPHLZKJiBBSOxy49JyhpW7LaOXTpKZVzBGOzuEQhZgwne\nzsGLR5kMKxiebT0Oh7KGEL6FwxeQAhlVMDD7ObUJNuJTR2OXk8IZQTAkqzYVCjTo7wlOQhZP\nMXpgOJZrahRm2D8QmIQsHmbkwEAs1FQqxsB/fAKauTzEuIEhSFdUK8TQf24Cmr48wKiB/lme\nqViA0f/8DDSHuZsxAz1z8IqqjT/888xA85g7GTHQJ+mKyo0/AbKVYPyqUBQDBvojXVG9sedA\nzkloQnMPwwV64uAVjL7HZP7+Y1eHkhgt0AfpClojz4Ps3968pjODBfKTrmBvavlq9BpREGMF\nMnPwiq7aobJe3LzjcAbx11lqloMXK5+xp0If33/sOlEMQwVykq6409WIOaat9TFgve4vbiWw\nQkzvAFZvr8r0GCmQj3RVsZRWszTfHEdB+09Kr81s85Jmm4uHvTdpub9/08zaR6WLP3a3WRyv\nvqXX/eUirdqwNWQ1soqfr9JF+19ef/JlYWukQDYOXtXtsD3PrwJWe8Pu/9n5Uav2ttfDff+u\nA9bHMqXlen91mWapOWSsXcD6N3BN8okfsL49TsAiGyMFcpCuqte+lbc65KrtKWC9fez+31yO\njXlab9rAtctS24/t58O3bahqXj+Oj1qkYw7bbmeX8aww08xXo9eLUhgo8Dzpit0g+NhuvwSs\n7VWE2m7P1/eP/hqwlp8Bq1lv347JalXuESwBi6oZKPAkB69oXeWqDgFru/1y78VbhKeHLJpt\nwfF97HJ3/P5356vRK0YhDBR4SrG7H5ld5KrVdvlTwJqn1SY1NwPWLmKdPuQ+273Ee5pt/6Xl\n7rIZtB7ZjD8z7o9LAhYZGSjwOAev+PQZsOan30a7FbD2H3JfXgasJl28B3g8TcPh9Ayr4+ka\nXgetRzbjz42eAtb4FaMMRgo8SLri0mfA2szT7P2ngHU+TcPpOavmxomuXps0W+0uV7M0exuk\n+NlFmB1dyuAAFn0xUuAh0hX8JsIEEbAYk5EC93PwCn4XY4Z0P6tV6vjwKDWjAIYK3Em64m4p\ndT1N+EQEqWkPxQhSMwpgrMBdKtoj4WFRpkn2ckSpGAUwWKC7mg5BwOPizJPMJYlTMeIzWqAj\n6Qo6CjRVck5bSwD3MFygE0srdBVrsmQrTaxqEZ4BA39z8AruEGy65Jm+FgHuZMTAH6QruEu8\nCfP8HLYKcDdjBn5lXYX7hJwyz01kywAPMGrgZw5ewd2CTprHZ7NlgIcYN/AD6QoeEHjaPDCn\nqzo9LHkZOXCTVRUeEnvm3BOYhCueYvTAd9ZVeFABUyd1NHY5KZwRBF9YWMnl4Q/9ZC3FoAou\nOuRlMsAV6YpsHh9L5Y7CcksOmZkMcObgFRk9M5hKHYillhvyMxvgSLoir+fOvJSrFMMqtNjQ\nA7MB9qQrMntyRBU5IIssNPTDdAAHr+jDs2OqxDFZYpmhJ6YD1ZOu6MPzo6q8cVleiaE/5gOV\nk67oR4aBVdrYLK280CsTgpo5eEVfsoyswoZnYcWFfpkQVEu6okd5BldRQ7SowkLvzAgqJV3R\np1zDq6RhWlJZoX9mBEB22ZbW2Gu0P+MHPzINAHLLuLLGXKT/ylFyFhj/AJllXVjDrdJ3JCch\ni4oZ+wCZ5V1YAy3TjxyWErKolHEPkFfudTXGOv1MUBKyqJAxD5BX9nU1wEL9fEASsaiMEQ+Q\nVQ/L6tgrdZ5wJGJRFeMdIKs+ltVxl+pKTjoBWRnuADn1s6qOuFbnPPDkIBb1MNgBcuppVR1t\nsc78jW061MJYB8iot0V1pNV6ip/YhyEY6gAZ9beojrJcT/AT+zAMIx0gnz7X1DHW6+l9Yh8G\nYqBTsPYDs+vFjTtWs9Qsd5ebRUovQ5eKmvW7pA6/YE/uE/swGOOcwl39VtIxba32f9Bjud00\n7aWExXB6XlIHX7EFLHiUcU4QKa1mab45Jqb2n5Rem9nmJc02Fw97b9Jyf/+mmbWPuvzbaO3x\nqv2VRXptQ9Z2uXvsOt06xAW96H1FHXrJ7vL9zlMwdfxbhTYeamCcE8RhaZ5fBaz2ht3/s/Oj\n9semXg/3/bsOWB/LlJbr/dXF/iVm25nxzbD6H3HDjulO+erL47o+BybOMCeIlBb7o06XAevt\nY/f/5vIn4nlab9rA1b4B+LH9fPjOMjWvHxevt0zv29TsbvUOIYMZYkEddNF+4GhUp/LZeaiA\nYU4QKX1st18C1vYqQm235+v7R38NWMuLgLU8HefyGSyGM8iCOuSqLWDBwwxzgrjKVR0C1nb7\n5d6LtwjbNwnfdv82ab1d+9scDGWgoTbgiO4UsK4+dtWtcCYlFTDMCeIiV622y58C1jytNqm5\nGbB2Eev0Iffdw97bi3+7gLURsBjKUENtuCHdJWBdfwZLwIIjw5wgPgPW/PSbSLcC1upw/oWL\ngNW0n3Y/OZ6mYXl8ibW3CBnQgLlnsG/19zdK1w/zDiEcGecE8RmwNvM0e/8pYJ1P03B6zqr5\nfh6G5pTRVvPUvA5UAaoX7MNRA32f64DlABacGOcAOcQ7gcIg30bAgtuMc4AMIp4CdJBvczoV\n3Zf3Cp96TZgAA50SpNT1FNEwksFH5zDfsIfvYh5TByMd4HkjrKWFJiy7DpUw1AGeN8ZaWmTC\nsulQC2Md4GnjLKUDJayM38b7/NTDYAd42khLaZhPug/9QhCf4Q7wrNFW0qESVpbv4/AVVTHe\nAZ413ko62BlHn/5G4hWVMeIBnjTmQjrcX8156juJV1THmAd40qgL6ZB/AvHR7yVeUSGjHuA5\nI6+jg/4NxHvP+OsUwVTLuAd4yujL6PAnkf/zbyv8/QiYOqMf4CnjL6Pj/RLjT8YqEMRhGjCi\n0YeffYDnRRhEEcoAXDEtGU2IdONnbZ4VYgSFKARwwaxkLGHGnozFM4KMniDFAE5MSsYRK9TI\nWDwsytCJUg7gwJxkFPEGnozFQ+IMmzglAbamJKMImmVkLO4XaMwEKgpgRjK8yDEmctmIKNSA\nCVUYqJ0JydCCjzmHsbhHrNESqzRQN/ORYZUQX2Qsuoo2UqKVBypmOjKoUgacjEUX8UZJvBJB\nrcxGBlRUapGx+FPAIRKwSFAnk5HBlBdYZCx+FXJ4hCwUVMhcZChljjUZi5/FHBsxSwXVMRUZ\nRsE5peCi06uoAyNquaAuZiKDKHugOYzFLWFHRdiCQU1MRAYwgXwiY/FV4BERuGhQDfOQ3k0l\nmshYXIk8HCKXDSphGtK3KY0xGYtPsYdC7NJBDcxC+jW5RCJjcRB8HAQvHkyfSUivJjnARCwK\nGNrhCwgTZw7So8kmEYexqlfAACigiDBlpiD9mfTokrHqVkLvl1BGmC4zkL5MP4DIWPUqo+fL\nKCVMlAlIPyrJHjJWpQrp9kKKCZNk/tGLigaWjFWhYrq8mILC9Jh+9EDkYNqCDvDUzdjFhDqY\nauRnVDFtEUf4HclJyIIhmGbkZu1m6qIN8QcSk5AFfTPFyMuqzeTFGuOPJyWTFfpkgpGVAcX0\nRRrlz4Ukh7GgP2YXGVmtqUCgUZ5hxpm00BNzi3yMJioQaJjnKUqgCsGUmFrk4idhqhBmnGeb\ncaYu9MHEIhNDiSqEGeg5CxKmUjAh5hVZ+BmYSkQZ6XnLEaVWMCGmFRmIV9QiylDPXY4o9YLp\nMKt4nlFENYIM9vzFCFIxmA6Timc5fEU9ggz2PooRpGowGeYUTzKErv2QN2/fvF78+lr/jk/6\naG4+e7NI6eWesvG0GMO9n1LEqBtMhinFUxy++uqugHW6dbG+cWebnw7X5l+fvf9607R/T07C\nGlKQ4d6lGOeTtKfU7Q8PBqkcTIUpxRPEq+9Sem+at+2xcfb/vDXN+/HKbLO/8j5Ls9Vx5zs8\nabE5XF7shemUq15nhyvHZ51edpmW23X6/RgYeQUZ8B3TUvry9fOvCnRnSvE4o+eGQ0R6vwhY\n76fUtNr925yupLQ+B6z1MqXlx5eAtTgG2HVa76+cnnV82e1M+w8tSIs/EJY6lTxI9WAizCge\n5fDVTe2bdi9pfhGw5vtbjleWhyvrXWz6d9mGHy9NWn5/rfbf2cvhyulZ6aRZpsY7hAOKMuIF\nLCiBGcWDDJ3bUvrYfrSB6DNgXdzyeWWfj74HrKsjWKd3As9h7fCsdEXCGk6UMd8pYF197Kpb\nyaPUD6bBjOIhDl/9pG2ZrwFrezNgpXMz3nyL8CpXpas79/82+yNaOmIwYZq6S8C6/gyWgAXD\nM6N4hHHzo5ReT28Rrk5vCC5PVy7eIjw++HS5+Lj5WtuLXPX5rOMd/3ZfbwSs4YRp6q5vEd4Z\nsMLUD6bBlOJ+NvVfHOLQan9uhfNn2/dXXnf/zs63LNqDUO0nsX44TcNFQ198yH3x+fXaW4SD\nCjTq/y7KdcByAAtGYEpxL/HqVym1Z2XYXdnM0+xwdob2vA3Xp2l4m6Wm/Uj7qvn1NAvXAevz\nWSereWpe+6gDtwQa9wIWFMCU4k6GzMNS2mxX7WfbKVCogd8hYZ0+rtft4V0fBHRmTnEXh6+e\nsNi/p/ftZAwUIdbIz1+aWPWDCTCpuIfx8pR/6fo9PsoRbOgLWBCeSUV3Dl9RrWhjP3d5otUP\nymdW0ZV4Rb3iDf68JYpXPyieaUVHhgr1ijj6M/7E44cn6IF5RSdWYGoWc/hnmpUmN/TCzKIL\n44SahR3/GbKReAU9Mbf4myWYugWeAM9NzmRuQ2/MLv5kkFC32DPg8ZAkXUGfTDD+YBGmduGn\nQLo/ZD3wFOAuphi/sghTvTLmwB2JSbiCIZhm/Mb4gHJmQepm7GJCHUw1fmYlzu/hj8tkLQV3\n0PTAI6wd/Mjg6MHDjao3xqLlgUdYO/iBw1d9eKJR9cc4tDvwEIsHN4lXvXjunEW5SsEdtDrw\nGKsHtxgX/XiuXfXKCDQ68BirB985fNWTZ9tVxwxOiwMPsnzwjUHRlwx/OC5DKbiDBgceZPng\nC0dJepOjZfXOoDQ38CjrB1fEqx5laVsdNCStDTzK+sEl46FHmRpXHw1HWwMPs4Bw5vBVr3K1\nrl4ajKYGHmYBgWHkm2tmLUB4lmoYRM6pZtoCRGelhkFknWrmLUBwFmoYQuaZZuICxGadhiHk\nnmlmLkBolmkYQP6JZuoCRGaVhgH0MNHMXYDALNLQv17mmckLEJc1GvrXzzwzewHCskRD7/qa\nZqYvQFRWaOhdb9PM/AUIygINfetxlpnAADFZn6FnvU4yMxggJMtzKdLtrrp983rxyyu9Nmm+\n2j+1dby49TKvs9Qs7y8pX/Q7yUzh+13Nj+vJ8uvUWTaHGbFZpPSyv+Wj0f7AbVaHUtwVsE63\nLtbf73vZ56n1dn0VsJbfn/+6v+O3/YYu+p5j5vDdrmbN9RT6beosj1Nl07SX+4Q1/2FeAlgd\nSpHSe9O8bY87wP6ft6Z5P16ZbfZX3mdptjoemzo8abE5XJ6PUqW02YWrf9u39Pr54q/N9vzs\n08sv0qpNYYPVcKp6b0Fd9KP3Jp2OOM13M2Ez38+Iq0O2xy9WnabO/ueSXdBa7i7bHz1eZyYI\n8AOrQykO6/z7RcB6Py39q92/zelKuwl8bgnr3c/cy49bu0Sz2yVmqTlkrI991jo9e3vxQ32b\nxHjKAFPMLP7Bfki/7o8zpTTbbmft5fxWwDoM/tXvU2e2nzqz3eXxuevkJxDgJ1aHUrRvSbzs\nNodzwJrvbzleWR6urA+R6Lzqf7w0X97+eznuGIt03H3atz7af0/PTuc9ZdbuSjxliClmGt+2\nG9Kb4xDeH+JN6WP/xfe3COe7WbL8nF5736fOpg1os802NcvUtO8Qzl5+eusewOpQinZv+Dhs\nEtvDPxe3fF5pNd93iasPsre3NLuA1ay3b4fdp/l3+A6HZ18ErN0P9o5gPWeYGWYe33Q+Evuy\n/7DU7oeL+ev2VsC6mFWn279PnXX72avmeIS4/almvhWwgJ9YHUrRLuRfA9b2ZsC62CVuvc9x\neLXZ+VW37+ntcP3iAyi7fxbN1v7xtIHaTzfdchq97+nl8CHF18Ws/ezU7YD18dfUOb1F2Bw/\ni/VtWgGcWRxK0b6bd3yLcHV6Q3B5unLxFuHxwafLxcfXF1rsHtR+Sne2e533fdD6d3ja57OP\nz/+3e9B7avqv2pQNNsHM5BvmabVpR3CTNqvznOj0FuGtqXP6kHs7YTYCFvA7i0Mp0vFTuIcP\n7J4/0p4O51OYnW9ZtBvK4a29H0/T0GyOZ2Fof2vw+Jndz2cfd5n1+UNaPGjA+WWj/24/pJeH\nD7c36Th3LubH3v6Lz9/w+G3qnE7TsD6+RdjS7MAPrA6lSKk9K8N2/6vms8PZGdrzNlyfpuHt\neGrQVfPL+at228S/9jfQX5vjWRlOe8TblxOLtr+5/tZPbWox6Pwymb85naZhlhab3bWPf4ez\nL1zNj8MXx9M0/D512lPvtrlqNT/9Aq6ABfzE6jAB7ZmtVt7LC2jg6WU2A4RhSZ6AxfGdC6IZ\nenqZzgBRWJGn4F/yRwMjGn52mc+dXZ6NBCA/ywv0ZYTZZUIDxGA9hp6MMrnMaIAQLMfQk3Em\nlykNEIHVGPox1twypwECsBhDP0abWyY1wPisxdCLEaeWWQ0wOksx9GHUmWVaA4zNSgx9GHdm\nmdcAI7MQQw/Gnlhjf3+A2lmHoQejT6zRCwBQN8sw5BdgXgUoAkDFrMJTka0n/Xm2DCI0YYQy\nxJSjZcwS4A9WiYnI2pE2jyfFaL8YpYgnU7uYJcCvrBHTkLsfbR5PCdJ6QYoRTL5WcbAX+IUF\nYhry96PN43FhWi5MQQLJ2yZmCfATy8Mk9NONNo8HxWm3OCWJInuLmCXAbRaHKeitFx3GekSk\nNotUlgj6aA+TBLjF0jABvXai3eNesRosVmnG1lNrmCTAdxaG8vXdh3aP+wRrrmDFGVV/bWGS\nAF9ZFsrXfx96p/AO4ZoqXIFG0/OhXg0NXLImFG+YLrR7dBWvoeKVaBy9t4NJAlywIpRusB70\nE3onERspYpmGN0QrmCPAJ+tB4QbtQNvH30I2kY4bjKYGjqwGZRu6/2wff4jaPlHLNZwBD/UO\n9Z2A0KwFZRu+/7xT+KuwjRO2YAMZsv7mCLC17BZunO6zffwocMsELtoAHOoFhmYZKNlovedH\n9NtCt0rowvVshLqbIlA7i0DBRu08+8cNsdskdun65EgvMDxLQLnG7jv7x1fRGyR6+foy4pHe\nsb4zMD4LQLnG7zvvFF4L3xrhC9iLMWtthkC9TP9ixeg6G8hZAU1RQBGzG7nOfgqBWpn7pQrT\nczaQkxLaoYQy5hWgxmYIVMnML1SojrOBtMpohDJKmU+M+pohUCHzvkzR+s0GEq9PflBIMTMJ\nU1szBKpj1pcpXr9V/05hMdUvpqAZRKpr7RMEqmPOFylmt9W9g5RT+XJKOjF1TxCojhlfoiC9\nlroZu5jDiFrNjp0UtfjPGf8XCKttemDsFYhHROi0OzaGKvaQkDW8p+Wn2EvjngDLBIHKmdjl\nGb3PHtgQJr+HxKvdAy0+sV4a8091miCASV2ecfvs8Y1gyjtItKrppdH6RNMDB6Z0cQr+E8/T\n/Sk9Vr2e7aVc5RhViX/geboTBGpkPpem8D+sNs0dJFSlnm/iKXTSKFUwQYAzs7kwo+arQK8S\nS6A65dmgi9/mx8lXeV6l9LYHDszlsozYX9nW/eltIIEqlK0oger0gDFKn29cl932wJGpXJbx\n+ivnd57aqAtTn5zZteQcPEq+yvlaBbc9cGIiF2Ua+Wpqwy5MbTIXJEy97lV6vsr/csAIzOOS\nTCVfTWvchalL9oKEqdl9JpCvim174Mw0Lsh08tWkBl6UqvRQjihVu8sk8lWZTQ9cMo3LMaV8\nNaGRF6YiemlvGvmqyKYHrpjF5RjvL38U9KrDi1IPvTQaTQ/cYBIXI/YBrItzUHf8s2oTGXph\nqqGX9qIewKqg6YFrJnEpxjwDVreHpItHd3zKBESpRtcte+K9FPUEoxU0PfCFSVyI+Pnq6no1\nP6GHqYReakXOV1fXp9f0wFfmcBnG7KdHftiuZv+IUomHGnxyvTROYQUs4BZzuAijdlOn/ePL\nx0pq2T/C1KFbg0+8l0Yq670TpONnsIpqeuA7c7gI4QPWxUdMOj5lGmMvTB26fc56O+leGquo\nd04QR7CgEuZwCcbtpa7vgKTrLzO8bHiB6qCXRivqnU3vQ+5QCZO4AGN30t/f/3rP6FbesWuV\nQaQq3B2wptZLoX8NRMCCCpnE8Y3eR3cGrI7lHb1azwtVhcp7KfavgQhYUCGTOLwAf3aaEAAA\nHZVJREFUXdRhAzl+bjcdrnb4EG+Aaj0rWBWq7qXo76JfNH3HD7kX0/TAD8zi8CJ0Uf4yRKjV\ns4LVoYfiBKvhz8YuaM1tD/zALI4uRA8JWDeEq0K9vTR6OetteuBHpnFwQToodzGCVOsp4eqQ\nvUDhaviDAOWstu2BH5nGsYXpn7wFCVOtJwSsQ+ZOCljDuLQ98IV5HFqg7sm45E9j94hYiTo7\nKUZJ62x74GdmcmihuifTsj+R3SNoLSrspDBFrbDtgV+Yy5FF650MS/9kdo+w9ej4h+5+f4kc\nBRlIpLKaIMCZ2RxYwM55bvnPsPdHEboiz/ZSrnIMIVhhTRDgxHyOK2bfPL4HTGnziF6Vanop\nXmmraXrgD6Z0WHG7ptuZqJ99SmgFVOaBFi+vl2IW1wQBtlEXKLbRu+aODWGCe0ch9bmn5Yvs\npcAlrnuCANvQK1TlCuiZ9McftPvr/nIVVKeOnVRQjc6iF7reCQJs4y9R1SqoY9JPxi5Ybwqs\n2RQ7qZSyT7Htgb+Z4zHpl8j0TgR6AQjNIhWSbolM70SgF4DYrFIh6ZbI9E4AOgEIzjIVkV6J\nTO8A8CebRUA6JTK9E4FeAKKzTsWjT0LTPQHoBCA8C1U4uiQ03ROATgDis1KFo0tC0z3j0wdA\nASxV0eiR0HTP+PQBUAJrVTA6JDb9MzpdABTBYgUE54/NAOWxQgFR+XPJQLEsTUBEdyQnIQuI\nx7IERPNAYhKygFgsSUAsDyclEQuIw4IERPJUSnIYC4jCagSEkSEgiVhACNYiIIhM2UjEAgKw\nEgEhZMxFIhYwOusQEEHetUjEAkZmFQICyL4UWduAUVmEgPHlX4msbcCoLELA+HpYiSxuwJis\nQdDRR9NOl80ipZdbd/94B3/rYyGyuAFjsgbBr9aL07V5+8HpTdP+TZbrILX/QPWtO+ion3XI\n6gaMyBLUg19+gWm/W3f7BafXJs1Xu8tlk5plppKx89bMNm0XpLRpZtvtapZmbTtvdvlpsTlf\nHrSHpY5XX2ft1WVabtep7cb34xOPHXq+g7t1mBHp/McGU+r2hwetbsCILEE9+GXt77AtHI+Y\nvOw3kfVu325JWNmsds3ZHAJWSv/2X6a0C0qz9nJ+vmx97Fp/uT5cX6d1+6xZunidtoO2x16d\nmUsP69J0Xx/zyHMAhmMFyuytad4Pu/f28M/hOEl7IGS+Of4Uvr/vdOBkt7nP2ruOPo+Y7J63\n29P/bds9fO2kPvnM00ubWtsWXm4/dl8ud1/O2y8/9vefLrftQanm9fOL2cuhP5vdrS/711kf\nO+jodAd3e+BoVKcZYdoA47EC5fV+evfiImC1x0nm7cXsImB9Hjg5POH7EZNDsGq2s/3lbLwq\nTU0boD4OPfOxveiol10vvG7Pl9t9wFqeAtZyfu7P/UetjqnqHLBOd3C3+94h7PqUzo8C6IEF\nKK/28MjLl4DVHifZ2VzdfHHgZNGmrf2zL4+YvByj2qZ9y2q2uf3tuN9FwDp8uT18uX1dzPYf\noTpdbr8E3kN/NKcjiqcbjq9xvoO7dT2Cla6/zPLCAP2wAOV1vXufj5Ns1y/zLzdf3n8OWJ9H\nTLYvTVo2abtufzmtWY9RmWm6eIvw8OUx6bbOn6I+Pfrj/JbtIU/92+WozSEif3bK/iGfd3C3\nrq12b8DSG8B4rEB5fR4PuU5S2/f0svl28/UDW5cfqt6/3MxbhLm9tkcEzz3z+Vn1/bu4i/Pl\nyfk0DftnrE/vBB6euDjdfr6D+919QErAAqKzAuV1OB6y371Xl8dJmrRZ/fQW4fbmEZPF/jcI\nlz7knt35NA37L0+/bfDx73B6htPlDYffTpinZv8ZrbfZ9fkzPu/gbn+P7+u3COUrIDxLUF6r\n0wdz5lefdt//7n97HvAm7X/v7OLAyZeAdX2ahmbjNA25tb+euUrN2MXgUreA5QAWUBBLUGbv\nTfO2P+H3PM3O52toP6q+2Oxi0qpJi6+nadheB6yTXbL61x5IeZ357f+cFhJrQB0S1uk3Cro9\nvOuDAHpiDaI2/5JT48eTfyWytgGjsggBAWRfiqxtwKgsQkAEmdciSxswLqsQEELO35X1e7fA\n2CxDQBDZliPrGjA6CxEQRZ4DTw5fAQFYiYA4ng9H4hUQgrUIiOSpgJTEKyAIqxEQy8MhSboC\n4rAgAdGk+49EPfAUgB5ZkoCI7khMwhUQj2UJiCp1M3YxAb6zNPUr34l97CL90UsAZGY/6FXW\n5rV590QvAZCb3aBXuf+8mu7qQe5G1UsACFi9yt+63oPKTy8BkJ2NoEf9NK7NOy+9BEB+toH+\n9Na2DpBkpJcA6IE9oDe9Nq3NOxO9BEAf7AC96blpbd459N2IegmgUtb/vvTfst6Dep5eAqAX\nFv+eDNOwNu/n6CUA+mHp78dg7eoAyRP0EgA9se73Y8h2tXk/aNB200sAVbHq92LgZrV5P2Lo\nRtNLABWx5vdh+Fb1HtT99BIAvbHg92CcRrV530cvAdAfy31+o7WpAyR30EsA9Mhan9+YbWrz\n7mjUdtJLAJNnpc9u5Ca1eXcxdiPpJYCJs87nNn6Leg/qb+O3kF4CmDSLfGYxGtTm/bsYzaOX\nAKbLEp9ZlAZ1gOQXYZpGLwFMlfU9r0jtafP+Qah20UsAk2R1zypYc9q8b4nWKHoJYIKs7TnF\na03vQX0Xr0X0EsDkWNgzitmYNu9rMZtDLwFMi2U9o2iNmb4Zu0QBxGsDvQQwQRbzfEK15e2N\n2vYdrPo3O0QvAZTPQp5NoKb8dYOuevcOVfXfeqLqXgKYAKt4LmFassPWXO/uHafef/dBvb0E\nMAGW8EyiNGTXTbnOzTtMpTs2f529BDAFFvBMYjTkPRtyhZt3lBrf0fQV9hLAJFi+84jRjneW\norbNO0h172z22noJYBos3lnEaMb7SxGj3AMJUlm9BFADa3cOMVrxkVLEKPkwYtRVLwFUwdKd\nQ4hWfKgQIUo+jBhVfawUMcoOQHdW7gxCNOKDhQhR9iHEqOijpYhRegA6s3A/L0YbCli/ClJP\nAQugEhbup8VoQjv3r4JU8+FiBCk/AF1ZuJ8VpAVt3b8KUsvHixGkAgB0ZN1+VpAW/K0Yv/9p\nwuxFCShKJR/upTA1AKAb6/aTojTgHxHql78qnL8s4YSp48O9FKcKAHRi3X5OmPZ7OEGFqUF/\n4lTx8Zwbpw4AdGHdfkqc5hOwfhSohgIWQC2s288I1Hq/bd11fwYrUgUf7qVQtQDgb9btZwRq\nvV+27so/gxWpgg/3UqhaAPA36/YTIjXeHwmq3oAVqn4P91KsagDwJ+v240K1nYB1W6zqCVgA\ntbBuPyxW0wlYNwWrnYAFUAvr9sNiNd1ve3O9H3KPVrmHeylcTQD4nXX7UdFazh97viFc7fzJ\nSIBKWLgfFK7hBKzv4lVOwAKohIX7MQHb7aEiBaxHPhEr91iZItYEgN9YuR8SsdkErC9C1k0v\nAdTB0v2QkM32QKFC1iOToHV7pFhBqwLAzyzdjwjaavcXK2hFsohaN70EUANr9wPCNtqdBfv1\nvACli1u3O5t90r0EMFkW7/sFbrN7NuNpb9yhK3dH00+7lwCmy/J9v9Bt1nVDnvjGHb12HZt/\n4r0EMGEW8LtFb7Lfzwje9SFlK6B6f/fB5HsJYMos4fcqocXSz3935Ze7JqSMGv7cF3X0EsCU\nWcXvVE6DpXS1TX/5ctJKquV1v9TUSwCTZim/T3ntlerbs0usa329BDBtVvT7aK/49BEAo7MZ\n3UVzxaePABif3egeWqsAOgmA8dmN7qCxCqCTAAjAdtSdtiqATgIgAvtRd9oqPn0EQAg2pM40\nVXz6CIAY7EhdaakC6CQAYrAjdaShCqCTAAjCltSRhopPHwEQhT2pG+0Unz4CIAybEgBAZgIW\nAEBmAhYAQGYCFgBAZgIWAEBmAhYAQGYCFgBAZgIWAEBmAhYAQGYCFgBAZgIWAEBmAhYAQGbT\nDljpdvVu37xe3Hzwv4sHfzQ3n7lZpPRyb9no3WqWmuW27e/Wdvt6/BoA+iZg3b71lLba7HS+\ndf71mfuvN027f0tYY1qsv9+22ueq5XZ9DFiv+4vbMRoAspp6wHpvmrftMQjt/3lrmvfjldlm\nf+V9lmar42GO4/POsSpdZqrX2eGL4zNOL7ncb+I27gektJql+eaig1J63XXMS5ptLh91/Gez\n641Fe8epB1LaNLPDQ/a3Hw9WHbpskV7bkLV9210evl61YWvI+gFQq2lvN4fd9v1ii34/bcDt\n4Y3mdCWl9UXA+limtDweEVlcHNhap8P2fHrG8SW3s2k3Yp8OvTG/CljtDbv/Z5ePOv4zOz76\nswfai3/tQ9Ztn318DVjt02a7ADxLzSFj7frw37A1BKBO084G7Rt3L1f793x/y/HK8nBlfdh2\nT0lquduNPy5f43Rt9nL44vSMdNLsnuIdwke079itDrlqewpYbx+7/zeXR5ou7jx0zEWfLbfH\nvvp4adL3D1gtd/F6se+kfcKaXeY2AOjN1APWx/bjy/79ecvnlX1GugpYy1sBa3kOaodnpCsS\n1gP2ielLB13c8Pmo4z+7aDx/3V712WdPHQLW5RGsbduXu4cvmvX27ZisVo5gATCEqQes7beA\ntb0ZsC639Mu3CC9uvnjg5ya+/7fZH0+Zdkv25Kpf/g5Y29fFrP2w2/c+u/UWYfsm4dvFayya\n7fXrAkBfpr3dtG8MHd8iXJ3eEFyerly8RXh88OfzPi5+d/B7wPp8xvHOf7uvNzbuR1zkqmMH\n3Q5YxztPT/neZyktPrZfzduP37XvC66272m266fl7rLpsToAcDTtWHCIRKv9+RXOn23fX2l/\nZ392vmXRHoi6ePvofFKsi0NVx4vPZxy/XnuL8FEXn427OCb1NWDNz9H20PCfPXA+VnXjNA3L\n49Nej6Ngff4sFgD0a+oBqz0rw3b/+/2zw9kZ2vM2XJ+m4e14+slVc/NUC98D1uczTlbzz99S\n4y6XJ2A4dNCtgPV558e/4+kY3j5PIfrLizefYbo5nNRhNUuzt1+eAAC5TDtg/SKlzXbl/SIA\noAfVBqzD7+77wykAQH7VBqztv+QP08V2OgHG2OUAgLvZvQAAMhOwAAAyE7AAADITsAAAMhOw\nAAAyE7AAADITsAAAMhOwAAAyE7AAADITsAAAMhOwAAAyqzZg5ai4P5PXr1zN6+8ZAjC0Wnee\nTPW2c/coZ9vqKAAGVem+k6/ajo70Jm/D6icABlTnrmPrLkD2VpWFARhMlVtOD1t37leklybV\nUQAMo8YNp48627kz66s9HcYCYAgV7jY9VdnGnVOfjamnAOhdfXtNfzW2cefTb1PqKQB6ZqfJ\nyftPmfTejHoKgF5Vt830XWEbdwaDtKGeAqA/tW0yA9TXxv2soRrQYSwA+lLZDjNMde3bzxmw\n+XQVAL2oa38ZrLb27ScM23a6CoAeVLW7DFlZbz89avB201UAZFfT1jJ0Xe3bjxil0XQVAHlV\ntLGMUFX79t3GajGHsQDIqZ5dZZya2rbvNGJ76SsAsqlmTxmtorbte4zbWPoKgExq2VHGrKdt\nu7PRW8o7hQBkUcl2MnI1bdvdhGglfQXA82wmA7Ft/y1KE8nDADyrjp0kRC3t2n8J1EA6C4Cn\nVLGPRKmkXftXsVpHZwHwhBp2kUB1tGv/LFzTeKcQgIdVsIXEqqJN+wch20VvAfCY6W8gMWqY\nfjJ2wcKI1BJ6C4AnTX7LGPvMlX/tzPbugwj111sA5DL1nWLEE7jfuQ/XvXGPf6IyvQVARhPf\nI0aq3uN7b6Wb9qi11lsAZDftHaLEP/Bc46Zd7h8yqrG3AOhg0vvDKJV7fsutb9Mer8J6C4Be\nTHl3GKNuebbbyjbtET8oF+dVAJgUe0NW2Zqzpn4ZL1+FeyEApmLCW8PwVct5KKOewyJjVVRv\nAdCf6W4MI+Sr0C8X1Wj5KvTLAVC4ye4LxeerCffNlbHOpBH+BQEo2VS3hQnkq+l2zqWp5Ks6\neguAria6K4xQrT6+5UR758JE3iDs7TUBKNQ0N4WJ5Kupds/ZlPLV9HsLgO4muSeMcgKs+x7V\n8S/ZTbJ7LgQOWBd/bLDrHx6cem8B0N0U94RxTuDe6UGnR6WOT5li91yIfAasrw/RWwDcYYJ7\nQuB8tb03YE2xf84mlq8m3lsA3GN6W8JIf+C522MErAsj/gXCDg/58q6ggAXAPWwJedwZsLp+\nBmvK/TNi1boewUrXX+Z4XQDqMLktIe55ldLWEaxLsQPWl8cJWADcZWpbQtxfS7vKVALWqDUT\nsADo2cS2hMAf60mXv+zvtwjHrdmdeVi+AuBO09oTwr/r5DQNRyNXrFvAcgALgEdNak+I/67T\nZ7Cq/ESjY9er468Rfj5UwALgPlPaE6K/6xTjNUMYvWJ6C4BeTWhTCP+uU4SXjGH8iuktAHo1\nnV1h9JpkL8DoNepLhIrpLQD6NJltIUBFMhchQI36EaNieguAHk1lXwhRj24nZx/+tYIJUjO9\nBUB/JrIxRKlGtnJEqVAP4lRNbwHQF1tDXnkOZUz5gEikquktAHoyjb0hUi2e324nvWEHq5ve\nAqAXk9gdglWi40lEsz+3BPEqp7cA6MEU9oeIdUgP7L01bNcxK6i3AMhsAntE3CrcsQdXsl1H\nrqPeAiCf8veJ4DVI6ffDI3/dPynhq6m3AMij+L2ikAqkn4xdsCEVU1m9BcCTSt8ySi9/TfQV\nANUofNMrvPh10VkAVKPsTa/s0ldGZwFQj6J3vaILXxudBUBFSt72Si57dXQWADWx7zEIAw2A\nmhS87xVc9ProLACqUu7GV27JK6SzAKhLsTtfsQWvkc4CoDKlbn2llrtKOguA2hS69xVa7Erp\nLQBqU8De9+MfhvNn4gCAkILnkjuSk5AFAAQROJM8kJiELAAggKh55PGkJGIBACOLmUaeC0kO\nYwEAo4oYRTLkIxELABhPwCCSp0gBKwYAVCJcDsl27MlBLABgJNFSSM7yRKsbAFCJYCEkb3GC\nVQ4AqESsDJK7NLFqBwBUIlQEyV+YUNUDACoRKYH0UZZI9QMAKhEogPRTlEAVnLb14vf7P5q2\nK95nafZ+6+7XWWqWPRQLAMYQKH90KMr13xrsVPZAFZy226fFOMeuefuAdduDaf39ia/7O/7I\naABQikD54++ipKuHdTvRVaAKliGl1SzNN8f2bf9J6bWZbV7SbPP5oFX6t/v3X1rtrs7SbHXI\nvulwhGr1+bDN4rOTXmft1X9puV3un3t+4P4hi91LrZ26DICpiLOldTmAdfm41LHscWpYhn1S\nSvOrgNXesPt/dn7UbH9n00at1uoYsFaXR6g+liktj9fXaR+fmuunrbfbi6C83icvAJiAOPGj\na0nSjWs5XpeD9o261SFXbU8B6+1j9//m8gDTS3rbvqWX9p2/9pjUKY/Nd5nplJOWqXn9OD1+\n9rK9es3TA9NR+5DLAAcARYsTP7q94Xf3Z7AC1bAMKX1st18C1sUNRx+7TDU/PfLy4a1m/5Bd\nwFqeAtZy/u01Dw+8CFjH9x0BYALixA9HsGL4mphuB6ztIr23x632N358CVjHx128RXi6/fMt\nwosHHj6D1Wy/fAMAKFicLa2ngBWngoW4yFWr7fLHgPW+i0ft+Ra+v0V44eP0IfdTnvr8kPvF\nA/cPae94Px76AoDiBcof9/4WoYDVi4uPSR0PMt0MWNvmEIc+P63epF1wWn0928LF2bHap38+\n+uKB+5c9nL/hdYD6AcAAAuUPASuEz4C1mafZ+88Ba5kO5wU9nqZhu2ravPT28/lC09WJRr8+\nsH2Ztx6qAwBjiJQ/OiSs08d2Oj4+Vv0AgEqECiD5CxOqegBAJWIlkNyliVW7Cbg8qwIA8JNg\nW2Xe4gSrHABQiWgZJGd5otXtf3t3mNu4DQYBVDfo/W9btJu0cWLFFDUyqY/v/dldbOI44AAz\nUBwLAFjEdCMk9uMnP8cCAAaZcIVkntKE3xgAsIgZd0jg2pPLVwDAOHMOkXP7yG+5AQBDzTpF\n+keSdQUADDbxGul4vyVv0QQATGDyPXJgMRlXAMAkbrBJtjajnyYAwAe7hMMSobGIAahMzXFU\nKDMmFgB1KTkOykXGD3YBqErDcUz4ftwCCEBF+o1D4oExsQAoSLtxxBV5MbEAKEe3ccBFcTGx\nAChGs9HuurSYWACUoteYg18pBKAQpUazq8NiYgFQhUqj1RuyYmIBUINCo9F7omJiAVCBOqPN\n25JiYgFwf8qMJu8Mite7A3B3mowW786JiQXArekxGgyIiYkFwI1pMV4bkxITC4Db0mG8NCwk\nJhYAN6XBeGVkRkwsAG5Jf/HC4Ij4lUIAbkh5MT0TC4C7UV38boqEmFgA3Ivi4lezBMTEAuBO\n1Ba/mSgfJhYA96G0+MVc8TCxALgLlcW+OdKx7Rn9xABgj5Ji1+hwvNpRdhYAs9JO7BmajQPL\nycgCYDqaiR0Db5BzfDEZWQBMRSvx3KgbPPcPJSMLgGloJJ4aEozzA8nGAmAK6ohnxuyriR4F\nAM7QRkwidu3JRSwAhtNFPDEgFskvKdUADKaK+Onm+0qsARhNE/HD7feVXAMwmCLiuwL7SrAB\nGEsP8U2JfSXZAAylhnhUZF+JNgAjaSEejAiEgQVANVqIr2Z9g9GH+xO2vV27aAMwjhbii1n3\n1cPHbB2fAwBvpYT436AbPB/7kOYnKdsADKOEGO3gTwgNLADmp4T4z6AwtF7B2j7/3vYaLNkG\nYBwlxKdRWWj9up8Dy2uwAJieEuLDuCg0fuXtyx8HX7cFAO+lhfhjYBJef+nHHxE2fYpoAzCQ\nFuJfI4PQNrAeXuRuYAEwNS3EP8bmoGFhfbywffvy97OPCQCXUUP8NT4G+a8/+jsCYG16iBlS\nkH4G478jAJamiJgiBNnnMMN3BMDKNBFzZCD5LOb4jgBYmCpa3iwRaHt79nc+EAD00kVMIxNG\nkQZgPG20upkSELj25PIVADNQR4ubLADn9lHjXaAB4GoKaW3znX//SLKuAJiGTlranMe/bW1v\n1t7/CQBwLa20sqlPf/t04iMAYAzdtLCbHP62Z/QTA4A9Smpdzh4ALqJkl+XoAeAqWnZVTh4A\nLqNmF+XgAeA6enZNzh0ALqRoAQDCDKwlOXYAuJKmXZFTB4BLqdoFOXQAuJauXY8zB4CLKdvl\nOHIAuJq2LW33Nn5u6gcAF9KtZR1YTkYWAETp1ZI6FpORBQAxOrWg7qVkYgFAhEYt59RKchkL\nAALUaTHnB5KJBQBnKdNSMuPIxAKAc1RpJbHTFAsAOEOT1pG88OQiFgCcoEfLCB+lZABANzVa\nRfwkRQMAemnRIvIHKRoA0EuL1nDFOcoGAHRSoiVcc4zCAQB9dGgJDcf45V6D29Z240HhAIA+\nOrSE18e4ff+wlpOXDgDookIraL0atX37d+BxAYCfVGgFrad4dGCJBwB00aAVtF2O2g7vK/EA\ngC4atILjV7BcwAKAC6nQCgwsAJiKCi3h6G8R2lcAcCUdWoKBBQAz0aE1NCysjxe5/3hDrBOP\nCQA8pUSLuOAgZQMAOinRIvIHKRoA0EuLVhE/SdEAgF5atIzsUbbcDBoAeE6N1hHcROYVAJyh\nSCsJ7SLzCgDOUaW1bOfHkXkFAGcp03JODaTAQAMA1GlB3SPJugKACI1a0nb8SlTHpwAAz+nU\nsg4sJuMKAKL0amnbH93/DwD00K0r2PaMfmIAUJOKBQAIM7AAAMIMLACAMAMLACDMwAIACDOw\nAADCDCwAgDADCwAgzMACAAgzsAAAwgwsAIAwAwsAIMzAAgAIM7AAAMIMLACAMAMLACDMwAIA\nCDOwAADCDCwAgDADCwAgzMACAAgzsAAAwgwsAIAwAwsAIMzAAgAIM7AAAMIMLACAMAMLACDM\nwAIACDOwAADCDCwAgDADCwAgzMACAAgzsAAAwgwsAIAwAwsAIMzAAgAIM7AAAMIMLACAMAML\nACDMwAIACDOwAADCDCwAgDADCwAgzMACAAgzsAAAwgwsAIAwAwsAIMzAAgAIM7AAAMIMLACA\nMAMLACDMwAIACDOwAADCDCwAgDADCwAgzMACAAgzsAAAwgwsAIAwAwsAIMzAAgAIM7AAAMIM\nLACAMAMLACDMwAIACPsbF+m9eLHQBg4AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 600,
       "width": 1200
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prp(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the 10-fold cross-validation error using a decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CV error= 0.9657  ; std dev= 0.1711\"\n"
     ]
    }
   ],
   "source": [
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-numeric(CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "     idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "     X_ts<-X[idx_ts,]  \n",
    "     Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "     idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "     X_tr<-X[idx_tr,]\n",
    "     Y_tr<-Y[idx_tr]                          \n",
    "     \n",
    "     DS<-cbind(X_tr,imdb_score=Y_tr)\n",
    "    \n",
    "     # Model fit (using rpart function)\n",
    "     model<- rpart(imdb_score~.,DS)\n",
    "     \n",
    "     # Model prediction \n",
    "     Y_hat_ts<- predict(model,X_ts)\n",
    "     \n",
    "     # Cross validation error = Mean Squared Error\n",
    "     CV_err[i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV_err),digits=4), \" ; std dev=\",round(sd(CV_err),digits=4)))\n",
    "\n",
    "CV_err_rpart_single_model <- CV_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create an ensemble of $R$ linear models to make predictions. Complete the code below so that:\n",
    "\n",
    "* The training set is resampled before building a model\n",
    "* The predictions of all model are averaged before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CV error= 0.9511  ; std dev= 0.1811\"\n"
     ]
    }
   ],
   "source": [
    "CV_folds <- 10\n",
    "R<-20\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-numeric(CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "     idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "     X_ts<-X[idx_ts,]  \n",
    "     Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "     idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "     X_tr<-X[idx_tr,]\n",
    "     Y_tr<-Y[idx_tr]                          \n",
    "     \n",
    "    # The predictions of each individual model is stored as\n",
    "    # a column of the Y_hat_ts_ensemble matrix\n",
    "     Y_hat_ts_ensemble <- matrix(0,nrow=nrow(X_ts),ncol=R) \n",
    "      \n",
    "     for (r in 1:R) {\n",
    "         idx_tr_resample <- sample(idx_tr,rep=T)\n",
    "         X_tr<-X[idx_tr_resample,]\n",
    "         Y_tr<-Y[idx_tr_resample]                          \n",
    "     \n",
    "         DS<-cbind(X_tr,imdb_score=Y_tr)\n",
    "    \n",
    "         # Model fit (using lm function)\n",
    "         model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "         # Storing prediction for the r^th model\n",
    "         Y_hat_ts_ensemble[,r]<- predict(model,X_ts)\n",
    "     \n",
    "     }\n",
    "    \n",
    "     #Computing ensemble prediction (via model averaging)\n",
    "     Y_hat_ts<-apply(Y_hat_ts_ensemble,1,mean)\n",
    "    \n",
    "     # Computation of CV error = MSE\n",
    "     CV_err[i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "     }\n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV_err),digits=4), \" ; std dev=\",round(sd(CV_err),digits=4)))\n",
    "\n",
    "CV_err_lm_ensemble_model <- CV_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the CV error lower than with a single linear model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(CV_err_lm_ensemble_model) < mean(CV_err_lm_single_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a decision tree as the base model. Is the CV error lower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CV error= 0.7982  ; std dev= 0.1428\"\n"
     ]
    }
   ],
   "source": [
    "CV_folds <- 10\n",
    "R<-20\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-numeric(CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "     idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "     X_ts<-X[idx_ts,]  \n",
    "     Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "     idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "     X_tr<-X[idx_tr,]\n",
    "     Y_tr<-Y[idx_tr]                          \n",
    "     \n",
    "    # The predictions of each individual model is stored as\n",
    "    # a column of the Y_hat_ts_ensemble matrix\n",
    "     Y_hat_ts_ensemble <- matrix(0,nrow=nrow(X_ts),ncol=R) \n",
    "      \n",
    "     for (r in 1:R) {\n",
    "         idx_tr_resample <- sample(idx_tr,rep=T)\n",
    "         X_tr<-X[idx_tr_resample,]\n",
    "         Y_tr<-Y[idx_tr_resample]                          \n",
    "     \n",
    "         DS<-cbind(X_tr,imdb_score=Y_tr)\n",
    "    \n",
    "         # Model fit (using rpart function)\n",
    "         model<- rpart(imdb_score~.,DS)\n",
    "        \n",
    "         # Storing prediction for the r^th model\n",
    "         Y_hat_ts_ensemble[,r]<- predict(model,X_ts)\n",
    "     \n",
    "     }\n",
    "    \n",
    "     #Computing ensemble prediction (via model averaging)\n",
    "     Y_hat_ts<-apply(Y_hat_ts_ensemble,1,mean)\n",
    "    \n",
    "     # Computation of CV error = MSE\n",
    "     CV_err[i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "     }\n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV_err),digits=4), \" ; std dev=\",round(sd(CV_err),digits=4)))\n",
    "\n",
    "CV_err_rpart_ensemble_model <- CV_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the CV error lower than with a single tree-based model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(CV_err_rpart_ensemble_model) < mean(CV_err_rpart_single_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature selection\n",
    "\n",
    "Two are the main approaches to feature selection:\n",
    "\n",
    "\n",
    "* **Filter methods:** they are preprocessing methods. They attempt to\n",
    "assess the merits of features from the data, ignoring the effects of\n",
    "the selected feature subset on the performance of the learning\n",
    "algorithm. Examples are methods that select variables by ranking them\n",
    "through compression techniques (like PCA), or by computing correlation or a more advanced similarity measure such as minimum redundancy maximum relevance (mRMR) with the output.\n",
    "\n",
    "*  **Wrapper methods:** these methods assess subsets of variables\n",
    "according to their usefulness to a given predictor. The method\n",
    "conducts a search for a good subset using the learning algorithm\n",
    "itself as part of the evaluation function. The problem boils \n",
    "down to a problem of stochastic state space search. Example\n",
    "are the stepwise methods proposed in linear regression analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with the output\n",
    "\n",
    "* The following code performs features selection by keeping the most correlated variables with the output. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"#Features:  1  ; CV error= 1.047  ; std dev= 0.1913\"  \n",
      " [2] \"#Features:  2  ; CV error= 1.0434  ; std dev= 0.1879\" \n",
      " [3] \"#Features:  3  ; CV error= 1.0388  ; std dev= 0.1879\" \n",
      " [4] \"#Features:  4  ; CV error= 1.0422  ; std dev= 0.1869\" \n",
      " [5] \"#Features:  5  ; CV error= 1.0216  ; std dev= 0.1637\" \n",
      " [6] \"#Features:  6  ; CV error= 0.9628  ; std dev= 0.1894\" \n",
      " [7] \"#Features:  7  ; CV error= 0.9532  ; std dev= 0.1825\" \n",
      " [8] \"#Features:  8  ; CV error= 0.9542  ; std dev= 0.1837\" \n",
      " [9] \"#Features:  9  ; CV error= 0.9567  ; std dev= 0.1822\" \n",
      "[10] \"#Features:  10  ; CV error= 0.9493  ; std dev= 0.1862\"\n",
      "[11] \"#Features:  11  ; CV error= 0.9522  ; std dev= 0.1864\"\n",
      "[12] \"#Features:  12  ; CV error= 0.9595  ; std dev= 0.1825\"\n",
      "[13] \"#Features:  13  ; CV error= 0.9547  ; std dev= 0.1869\"\n",
      "[14] \"#Features:  14  ; CV error= 0.9519  ; std dev= 0.1845\"\n",
      "[15] \"#Features:  15  ; CV error= 0.9482  ; std dev= 0.1812\"\n"
     ]
    }
   ],
   "source": [
    "# drop = F is used to preserve the structure of the data as data.frame (see https://www.r-bloggers.com/2018/02/r-tip-use-drop-false-with-data-frames/)\n",
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-matrix(0,nrow=n,ncol=CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "    \n",
    "    idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "    X_ts<-X[idx_ts,]  \n",
    "    Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "    idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "    X_tr<-X[idx_tr,]\n",
    "    Y_tr<-Y[idx_tr]                          \n",
    "    \n",
    "    # Compute correlation across all the input variables and the target variable\n",
    "    correlation_vector <-abs(cor(X_tr,Y_tr))\n",
    "    # Rank variables according to correlation with the output\n",
    "    correlation_ranking_idx <-sort(correlation_vector,dec=T,index.return=T)$ix\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        # Create a dataset including only the nb_features most correlated variables with the output\n",
    "        DS<-cbind(X_tr[,correlation_ranking_idx[1:nb_features],drop=F],imdb_score=Y_tr)\n",
    "        \n",
    "        # Model fit (using lm function)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        # Model prediction\n",
    "        Y_hat_ts<- predict(model,X_ts[,correlation_ranking_idx[1:nb_features],drop=F])\n",
    "        \n",
    "        # Cross validation error = MSE\n",
    "        CV_err[nb_features,i] <- mean((Y_hat_ts-Y_ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV_err,1,mean),digits=4), \" ; std dev=\",round(apply(CV_err,1,sd),digits=4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>7</li><li>1</li><li>15</li><li>10</li><li>2</li><li>12</li><li>6</li><li>5</li><li>8</li><li>13</li><li>3</li><li>9</li><li>11</li><li>4</li><li>14</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7\n",
       "\\item 1\n",
       "\\item 15\n",
       "\\item 10\n",
       "\\item 2\n",
       "\\item 12\n",
       "\\item 6\n",
       "\\item 5\n",
       "\\item 8\n",
       "\\item 13\n",
       "\\item 3\n",
       "\\item 9\n",
       "\\item 11\n",
       "\\item 4\n",
       "\\item 14\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7\n",
       "2. 1\n",
       "3. 15\n",
       "4. 10\n",
       "5. 2\n",
       "6. 12\n",
       "7. 6\n",
       "8. 5\n",
       "9. 8\n",
       "10. 13\n",
       "11. 3\n",
       "12. 9\n",
       "13. 11\n",
       "14. 4\n",
       "15. 14\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  7  1 15 10  2 12  6  5  8 13  3  9 11  4 14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_voted_users'</li><li>'num_critic_for_reviews'</li><li>'movie_facebook_likes'</li><li>'num_user_for_reviews'</li><li>'duration'</li><li>'title_year'</li><li>'gross'</li><li>'actor_1_facebook_likes'</li><li>'cast_total_facebook_likes'</li><li>'actor_2_facebook_likes'</li><li>'director_facebook_likes'</li><li>'facenumber_in_poster'</li><li>'budget'</li><li>'actor_3_facebook_likes'</li><li>'aspect_ratio'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_voted\\_users'\n",
       "\\item 'num\\_critic\\_for\\_reviews'\n",
       "\\item 'movie\\_facebook\\_likes'\n",
       "\\item 'num\\_user\\_for\\_reviews'\n",
       "\\item 'duration'\n",
       "\\item 'title\\_year'\n",
       "\\item 'gross'\n",
       "\\item 'actor\\_1\\_facebook\\_likes'\n",
       "\\item 'cast\\_total\\_facebook\\_likes'\n",
       "\\item 'actor\\_2\\_facebook\\_likes'\n",
       "\\item 'director\\_facebook\\_likes'\n",
       "\\item 'facenumber\\_in\\_poster'\n",
       "\\item 'budget'\n",
       "\\item 'actor\\_3\\_facebook\\_likes'\n",
       "\\item 'aspect\\_ratio'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_voted_users'\n",
       "2. 'num_critic_for_reviews'\n",
       "3. 'movie_facebook_likes'\n",
       "4. 'num_user_for_reviews'\n",
       "5. 'duration'\n",
       "6. 'title_year'\n",
       "7. 'gross'\n",
       "8. 'actor_1_facebook_likes'\n",
       "9. 'cast_total_facebook_likes'\n",
       "10. 'actor_2_facebook_likes'\n",
       "11. 'director_facebook_likes'\n",
       "12. 'facenumber_in_poster'\n",
       "13. 'budget'\n",
       "14. 'actor_3_facebook_likes'\n",
       "15. 'aspect_ratio'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_voted_users\"           \"num_critic_for_reviews\"   \n",
       " [3] \"movie_facebook_likes\"      \"num_user_for_reviews\"     \n",
       " [5] \"duration\"                  \"title_year\"               \n",
       " [7] \"gross\"                     \"actor_1_facebook_likes\"   \n",
       " [9] \"cast_total_facebook_likes\" \"actor_2_facebook_likes\"   \n",
       "[11] \"director_facebook_likes\"   \"facenumber_in_poster\"     \n",
       "[13] \"budget\"                    \"actor_3_facebook_likes\"   \n",
       "[15] \"aspect_ratio\"             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation_ranking_idx\n",
    "colnames(X)[correlation_ranking_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mRMR\n",
    "\n",
    "* The following code performs features selection by using the mRMR approach (Section 12.8 - Syllabus). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"#Features:  1  ; CV error= 1.047  ; std dev= 0.1913\"  \n",
      " [2] \"#Features:  2  ; CV error= 0.9989  ; std dev= 0.2005\" \n",
      " [3] \"#Features:  3  ; CV error= 0.9906  ; std dev= 0.1899\" \n",
      " [4] \"#Features:  4  ; CV error= 0.9931  ; std dev= 0.1916\" \n",
      " [5] \"#Features:  5  ; CV error= 0.9844  ; std dev= 0.1883\" \n",
      " [6] \"#Features:  6  ; CV error= 0.987  ; std dev= 0.1886\"  \n",
      " [7] \"#Features:  7  ; CV error= 0.9895  ; std dev= 0.1873\" \n",
      " [8] \"#Features:  8  ; CV error= 0.9842  ; std dev= 0.1875\" \n",
      " [9] \"#Features:  9  ; CV error= 0.9672  ; std dev= 0.1856\" \n",
      "[10] \"#Features:  10  ; CV error= 0.9679  ; std dev= 0.1861\"\n",
      "[11] \"#Features:  11  ; CV error= 0.9604  ; std dev= 0.1774\"\n",
      "[12] \"#Features:  12  ; CV error= 0.9601  ; std dev= 0.178\" \n",
      "[13] \"#Features:  13  ; CV error= 0.9586  ; std dev= 0.1817\"\n",
      "[14] \"#Features:  14  ; CV error= 0.9525  ; std dev= 0.181\" \n",
      "[15] \"#Features:  15  ; CV error= 0.9482  ; std dev= 0.1812\"\n"
     ]
    }
   ],
   "source": [
    "# drop = F is used to preserve the structure of the data as data.frame (see https://www.r-bloggers.com/2018/02/r-tip-use-drop-false-with-data-frames/)\n",
    "\n",
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-matrix(0,nrow=n,ncol=CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "    \n",
    "    idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "    X_ts<-X[idx_ts,]  \n",
    "    Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "    idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "    X_tr<-X[idx_tr,]\n",
    "    Y_tr<-Y[idx_tr]                          \n",
    "    \n",
    "    # Computing the correlation between input variables and output variable on the training set\n",
    "    correlation<-abs(cor(X_tr,Y_tr))\n",
    "    \n",
    "    # Initialization : No variables are selected and all the variables are candidates\n",
    "    selected<-c()\n",
    "    candidates<-1:n\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n) {\n",
    "        redundancy_score<-numeric(length(candidates))\n",
    "        \n",
    "        if (length(selected)>0) {\n",
    "            # Compute the correlation between the selected variables and the candidates on the training set\n",
    "            cor_selected_candidates<-cor(X_tr[,selected,drop=F],X_tr[,candidates,drop=F])\n",
    "            # Compute the mean correlation for each candidate variable, across the selected variables\n",
    "            redundancy_score<-apply(cor_selected_candidates,2,mean)\n",
    "        }\n",
    "        \n",
    "        # mRMR: minimum Redundancy Maximum Relevancy\n",
    "        mRMR_score<-correlation[candidates]-redundancy_score\n",
    "        \n",
    "        # Select the candidate variable that maximises the mRMR score\n",
    "        selected_current<-candidates[which.max(mRMR_score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        \n",
    "        # Remove the selected variables from the candidates\n",
    "        candidates<-setdiff(candidates,selected_current)\n",
    "    }\n",
    "    \n",
    "    ranking <- selected\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        # Create a dataset including only the first nb_features selected variables\n",
    "        DS<-cbind(X_tr[,ranking[1:nb_features],drop=F],imdb_score=Y_tr)\n",
    "        \n",
    "        # Model fit (using lm function)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        # Model prediction\n",
    "        Y_hat_ts<- predict(model,X_ts[,ranking[1:nb_features],drop=F])\n",
    "        \n",
    "        # Cross-validation error = MSE\n",
    "        CV_err[nb_features,i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV_err,1,mean),digits=4), \" ; std dev=\",round(apply(CV_err,1,sd),digits=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>7</li><li>12</li><li>2</li><li>9</li><li>15</li><li>10</li><li>14</li><li>3</li><li>1</li><li>13</li><li>5</li><li>6</li><li>4</li><li>8</li><li>11</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7\n",
       "\\item 12\n",
       "\\item 2\n",
       "\\item 9\n",
       "\\item 15\n",
       "\\item 10\n",
       "\\item 14\n",
       "\\item 3\n",
       "\\item 1\n",
       "\\item 13\n",
       "\\item 5\n",
       "\\item 6\n",
       "\\item 4\n",
       "\\item 8\n",
       "\\item 11\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7\n",
       "2. 12\n",
       "3. 2\n",
       "4. 9\n",
       "5. 15\n",
       "6. 10\n",
       "7. 14\n",
       "8. 3\n",
       "9. 1\n",
       "10. 13\n",
       "11. 5\n",
       "12. 6\n",
       "13. 4\n",
       "14. 8\n",
       "15. 11\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  7 12  2  9 15 10 14  3  1 13  5  6  4  8 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_voted_users'</li><li>'title_year'</li><li>'duration'</li><li>'facenumber_in_poster'</li><li>'movie_facebook_likes'</li><li>'num_user_for_reviews'</li><li>'aspect_ratio'</li><li>'director_facebook_likes'</li><li>'num_critic_for_reviews'</li><li>'actor_2_facebook_likes'</li><li>'actor_1_facebook_likes'</li><li>'gross'</li><li>'actor_3_facebook_likes'</li><li>'cast_total_facebook_likes'</li><li>'budget'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_voted\\_users'\n",
       "\\item 'title\\_year'\n",
       "\\item 'duration'\n",
       "\\item 'facenumber\\_in\\_poster'\n",
       "\\item 'movie\\_facebook\\_likes'\n",
       "\\item 'num\\_user\\_for\\_reviews'\n",
       "\\item 'aspect\\_ratio'\n",
       "\\item 'director\\_facebook\\_likes'\n",
       "\\item 'num\\_critic\\_for\\_reviews'\n",
       "\\item 'actor\\_2\\_facebook\\_likes'\n",
       "\\item 'actor\\_1\\_facebook\\_likes'\n",
       "\\item 'gross'\n",
       "\\item 'actor\\_3\\_facebook\\_likes'\n",
       "\\item 'cast\\_total\\_facebook\\_likes'\n",
       "\\item 'budget'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_voted_users'\n",
       "2. 'title_year'\n",
       "3. 'duration'\n",
       "4. 'facenumber_in_poster'\n",
       "5. 'movie_facebook_likes'\n",
       "6. 'num_user_for_reviews'\n",
       "7. 'aspect_ratio'\n",
       "8. 'director_facebook_likes'\n",
       "9. 'num_critic_for_reviews'\n",
       "10. 'actor_2_facebook_likes'\n",
       "11. 'actor_1_facebook_likes'\n",
       "12. 'gross'\n",
       "13. 'actor_3_facebook_likes'\n",
       "14. 'cast_total_facebook_likes'\n",
       "15. 'budget'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_voted_users\"           \"title_year\"               \n",
       " [3] \"duration\"                  \"facenumber_in_poster\"     \n",
       " [5] \"movie_facebook_likes\"      \"num_user_for_reviews\"     \n",
       " [7] \"aspect_ratio\"              \"director_facebook_likes\"  \n",
       " [9] \"num_critic_for_reviews\"    \"actor_2_facebook_likes\"   \n",
       "[11] \"actor_1_facebook_likes\"    \"gross\"                    \n",
       "[13] \"actor_3_facebook_likes\"    \"cast_total_facebook_likes\"\n",
       "[15] \"budget\"                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected\n",
    "colnames(X)[selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "* The following code performs features selection by first transforming the inputs using PCA, and then keeping the most relevant principal components in the model. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"#Features:  1  ; CV error= 1.2239  ; std dev= 0.2165\" \n",
      " [2] \"#Features:  2  ; CV error= 1.2183  ; std dev= 0.2192\" \n",
      " [3] \"#Features:  3  ; CV error= 1.022  ; std dev= 0.181\"   \n",
      " [4] \"#Features:  4  ; CV error= 1.0209  ; std dev= 0.181\"  \n",
      " [5] \"#Features:  5  ; CV error= 1.0224  ; std dev= 0.1802\" \n",
      " [6] \"#Features:  6  ; CV error= 1.0234  ; std dev= 0.1801\" \n",
      " [7] \"#Features:  7  ; CV error= 1.028  ; std dev= 0.1782\"  \n",
      " [8] \"#Features:  8  ; CV error= 1.0258  ; std dev= 0.1823\" \n",
      " [9] \"#Features:  9  ; CV error= 1.026  ; std dev= 0.1815\"  \n",
      "[10] \"#Features:  10  ; CV error= 1.0281  ; std dev= 0.1826\"\n",
      "[11] \"#Features:  11  ; CV error= 1.0199  ; std dev= 0.1797\"\n",
      "[12] \"#Features:  12  ; CV error= 0.9892  ; std dev= 0.1607\"\n",
      "[13] \"#Features:  13  ; CV error= 0.9447  ; std dev= 0.1834\"\n",
      "[14] \"#Features:  14  ; CV error= 0.946  ; std dev= 0.1851\" \n",
      "[15] \"#Features:  15  ; CV error= 0.9482  ; std dev= 0.1812\"\n"
     ]
    }
   ],
   "source": [
    "# drop = F is used to preserve the structure of the data as data.frame (see https://www.r-bloggers.com/2018/02/r-tip-use-drop-false-with-data-frames/)\n",
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-matrix(0,nrow=n,ncol=CV_folds)\n",
    "\n",
    "# Compute PCA on the full input dataset X and return the dataset transformed in the space of principal components\n",
    "X_pca<-data.frame(prcomp(X,retx=T)$x)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "    \n",
    "    idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "    X_ts<-X_pca[idx_ts,]  \n",
    "    Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "    idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "    X_tr<-X_pca[idx_tr,]\n",
    "    Y_tr<-Y[idx_tr]         \n",
    "     \n",
    "    for (nb_components in 1:n) {\n",
    "        # Create a dataset including only the first nb_components principal components\n",
    "        DS<-cbind(X_tr[,1:nb_components,drop=F],imdb_score=Y_tr)\n",
    "        \n",
    "        # Model fit (using lm function)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        # Model predict\n",
    "        Y_hat_ts<- predict(model,X_ts[,1:nb_components,drop=F])\n",
    "        \n",
    "        CV_err[nb_components,i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV_err,1,mean),digits=4), \" ; std dev=\",round(apply(CV_err,1,sd),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper method: Forward selection\n",
    "\n",
    "* The following code performs features selection by using a forward selection method (Section 12.4 - Syllabus). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Round  1  ; Selected feature:  7  ; CV error= 1.047  ; std dev= 0.1913\"\n",
      "[1] \"Round  2  ; Selected feature:  12  ; CV error= 0.9989  ; std dev= 0.2005\"\n",
      "[1] \"Round  3  ; Selected feature:  1  ; CV error= 0.9778  ; std dev= 0.2045\"\n",
      "[1] \"Round  4  ; Selected feature:  11  ; CV error= 0.9578  ; std dev= 0.2026\"\n",
      "[1] \"Round  5  ; Selected feature:  2  ; CV error= 0.9479  ; std dev= 0.1903\"\n",
      "[1] \"Round  6  ; Selected feature:  10  ; CV error= 0.942  ; std dev= 0.1851\"\n",
      "[1] \"Round  7  ; Selected feature:  4  ; CV error= 0.9419  ; std dev= 0.1871\"\n",
      "[1] \"Round  8  ; Selected feature:  13  ; CV error= 0.9407  ; std dev= 0.1907\"\n",
      "[1] \"Round  9  ; Selected feature:  9  ; CV error= 0.941  ; std dev= 0.1929\"\n",
      "[1] \"Round  10  ; Selected feature:  6  ; CV error= 0.9416  ; std dev= 0.1889\"\n",
      "[1] \"Round  11  ; Selected feature:  15  ; CV error= 0.9427  ; std dev= 0.1897\"\n",
      "[1] \"Round  12  ; Selected feature:  8  ; CV error= 0.944  ; std dev= 0.1901\"\n",
      "[1] \"Round  13  ; Selected feature:  5  ; CV error= 0.9427  ; std dev= 0.1847\"\n",
      "[1] \"Round  14  ; Selected feature:  14  ; CV error= 0.9453  ; std dev= 0.1811\"\n",
      "[1] \"Round  15  ; Selected feature:  3  ; CV error= 0.9482  ; std dev= 0.1812\"\n"
     ]
    }
   ],
   "source": [
    "# drop = F is used to preserve the structure of the data as data.frame (see https://www.r-bloggers.com/2018/02/r-tip-use-drop-false-with-data-frames/)\n",
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "selected<-NULL\n",
    "\n",
    "# Perform up to n (number of variables) round of selection\n",
    "for (round in 1:n) { \n",
    "    candidates<-setdiff(1:n,selected)\n",
    "    \n",
    "    CV_err<-matrix(0,nrow=length(candidates),ncol=CV_folds)\n",
    "    \n",
    "    # For each round, test all the candidate variables\n",
    "    for (j in 1:length(candidates)) {\n",
    "        features_to_include<-c(selected,candidates[j])\n",
    "        \n",
    "        # For each variable, perform cross-validation to determine the CV-error\n",
    "        for (i in 1:CV_folds) {\n",
    "            \n",
    "            idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "            X_ts<-X[idx_ts,features_to_include,drop=F]  \n",
    "            Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "            idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "            X_tr<-X[idx_tr,features_to_include,drop=F]\n",
    "            Y_tr<-Y[idx_tr]         \n",
    "            \n",
    "            # Create a dataset including only the first nb_components principal components\n",
    "            DS<-cbind(X_tr,imdb_score=Y_tr)\n",
    "        \n",
    "            # Model fit (using lm function)\n",
    "            model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "            # Model predict\n",
    "            Y_hat_ts<- predict(model,X_ts)\n",
    "     \n",
    "            # Cross validation error = MSE\n",
    "            CV_err[j,i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Compute the mean and sd of cross-validation error across all the candidates\n",
    "    # In CV_err matrix, every row represents a candidate, and every element represents the results of the i^th CV fold.\n",
    "    CV_err_mean<-apply(CV_err,1,mean)\n",
    "    CV_err_sd<-apply(CV_err,1,sd)\n",
    "    \n",
    "    # Select the candiate that minimizes the cross-validation error\n",
    "    selected_current<-which.min(CV_err_mean)              \n",
    "    selected<-c(selected,candidates[selected_current])\n",
    "    \n",
    "    print(paste(\"Round \",round,\" ; Selected feature: \",candidates[selected_current],\" ; CV error=\",round(CV_err_mean[selected_current],digits=4), \" ; std dev=\",round(CV_err_sd[selected_current],digits=4)))\n",
    "\n",
    "}\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_voted_users'</li><li>'title_year'</li><li>'num_critic_for_reviews'</li><li>'budget'</li><li>'duration'</li><li>'num_user_for_reviews'</li><li>'actor_3_facebook_likes'</li><li>'actor_2_facebook_likes'</li><li>'facenumber_in_poster'</li><li>'gross'</li><li>'movie_facebook_likes'</li><li>'cast_total_facebook_likes'</li><li>'actor_1_facebook_likes'</li><li>'aspect_ratio'</li><li>'director_facebook_likes'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_voted\\_users'\n",
       "\\item 'title\\_year'\n",
       "\\item 'num\\_critic\\_for\\_reviews'\n",
       "\\item 'budget'\n",
       "\\item 'duration'\n",
       "\\item 'num\\_user\\_for\\_reviews'\n",
       "\\item 'actor\\_3\\_facebook\\_likes'\n",
       "\\item 'actor\\_2\\_facebook\\_likes'\n",
       "\\item 'facenumber\\_in\\_poster'\n",
       "\\item 'gross'\n",
       "\\item 'movie\\_facebook\\_likes'\n",
       "\\item 'cast\\_total\\_facebook\\_likes'\n",
       "\\item 'actor\\_1\\_facebook\\_likes'\n",
       "\\item 'aspect\\_ratio'\n",
       "\\item 'director\\_facebook\\_likes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_voted_users'\n",
       "2. 'title_year'\n",
       "3. 'num_critic_for_reviews'\n",
       "4. 'budget'\n",
       "5. 'duration'\n",
       "6. 'num_user_for_reviews'\n",
       "7. 'actor_3_facebook_likes'\n",
       "8. 'actor_2_facebook_likes'\n",
       "9. 'facenumber_in_poster'\n",
       "10. 'gross'\n",
       "11. 'movie_facebook_likes'\n",
       "12. 'cast_total_facebook_likes'\n",
       "13. 'actor_1_facebook_likes'\n",
       "14. 'aspect_ratio'\n",
       "15. 'director_facebook_likes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_voted_users\"           \"title_year\"               \n",
       " [3] \"num_critic_for_reviews\"    \"budget\"                   \n",
       " [5] \"duration\"                  \"num_user_for_reviews\"     \n",
       " [7] \"actor_3_facebook_likes\"    \"actor_2_facebook_likes\"   \n",
       " [9] \"facenumber_in_poster\"      \"gross\"                    \n",
       "[11] \"movie_facebook_likes\"      \"cast_total_facebook_likes\"\n",
       "[13] \"actor_1_facebook_likes\"    \"aspect_ratio\"             \n",
       "[15] \"director_facebook_likes\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(X)[selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further preprocessing to add categorical variables\n",
    "\n",
    "Categorical variables usually need to be transformed with 'one-hot-encoding' in order to be processed by a learning algorithm. That is, for each value of the categorical variable, a binary feature is created, which is set to one whenever that value is present. This can be done using the `dummy.data.frame` of the `dummies` package.\n",
    "\n",
    "```\n",
    "install.packages('dummies')\n",
    "library(dummies)\n",
    "```\n",
    "\n",
    "In the following, we add some categorical variables to the peprocessing dataset. The set of categorical variables is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('dummies')\n",
    "library(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>color</dt><dd>1</dd><dt>director_name</dt><dd>2</dd><dt>actor_2_name</dt><dd>7</dd><dt>genres</dt><dd>10</dd><dt>actor_1_name</dt><dd>11</dd><dt>movie_title</dt><dd>12</dd><dt>actor_3_name</dt><dd>15</dd><dt>plot_keywords</dt><dd>17</dd><dt>movie_imdb_link</dt><dd>18</dd><dt>language</dt><dd>20</dd><dt>country</dt><dd>21</dd><dt>content_rating</dt><dd>22</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[color] 1\n",
       "\\item[director\\textbackslash{}\\_name] 2\n",
       "\\item[actor\\textbackslash{}\\_2\\textbackslash{}\\_name] 7\n",
       "\\item[genres] 10\n",
       "\\item[actor\\textbackslash{}\\_1\\textbackslash{}\\_name] 11\n",
       "\\item[movie\\textbackslash{}\\_title] 12\n",
       "\\item[actor\\textbackslash{}\\_3\\textbackslash{}\\_name] 15\n",
       "\\item[plot\\textbackslash{}\\_keywords] 17\n",
       "\\item[movie\\textbackslash{}\\_imdb\\textbackslash{}\\_link] 18\n",
       "\\item[language] 20\n",
       "\\item[country] 21\n",
       "\\item[content\\textbackslash{}\\_rating] 22\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "color\n",
       ":   1director_name\n",
       ":   2actor_2_name\n",
       ":   7genres\n",
       ":   10actor_1_name\n",
       ":   11movie_title\n",
       ":   12actor_3_name\n",
       ":   15plot_keywords\n",
       ":   17movie_imdb_link\n",
       ":   18language\n",
       ":   20country\n",
       ":   21content_rating\n",
       ":   22\n",
       "\n"
      ],
      "text/plain": [
       "          color   director_name    actor_2_name          genres    actor_1_name \n",
       "              1               2               7              10              11 \n",
       "    movie_title    actor_3_name   plot_keywords movie_imdb_link        language \n",
       "             12              15              17              18              20 \n",
       "        country  content_rating \n",
       "             21              22 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have an overview of the their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factor<-data[,factor_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1000</li><li>12</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 12\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 12\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>color</th><th scope=col>director_name</th><th scope=col>actor_2_name</th><th scope=col>genres</th><th scope=col>actor_1_name</th><th scope=col>movie_title</th><th scope=col>actor_3_name</th><th scope=col>plot_keywords</th><th scope=col>movie_imdb_link</th><th scope=col>language</th><th scope=col>country</th><th scope=col>content_rating</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3925</th><td>Color</td><td>Oliver Stone</td><td>Zach Grenier</td><td>Drama          </td><td>Michael Wincott</td><td>Talk RadioÂ     </td><td>Bill Johnson </td><td>listener|neo nazi|radio|radio station|radio talk show</td><td>http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1</td><td>English</td><td>USA   </td><td>R</td></tr>\n",
       "\t<tr><th scope=row>4806</th><td>Color</td><td>Paul Fox    </td><td>Jeff Seymour</td><td>Horror|Thriller</td><td>Dov Tiefenbach </td><td>The Dark HoursÂ </td><td>Gordon Currie</td><td>brain tumor|champagne|game|psychiatrist|weekend      </td><td>http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1</td><td>English</td><td>Canada</td><td>R</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 12\n",
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & color & director\\_name & actor\\_2\\_name & genres & actor\\_1\\_name & movie\\_title & actor\\_3\\_name & plot\\_keywords & movie\\_imdb\\_link & language & country & content\\_rating\\\\\n",
       "  & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t3925 & Color & Oliver Stone & Zach Grenier & Drama           & Michael Wincott & Talk RadioÂ      & Bill Johnson  & listener\\textbar{}neo nazi\\textbar{}radio\\textbar{}radio station\\textbar{}radio talk show & http://www.imdb.com/title/tt0096219/?ref\\_=fn\\_tt\\_tt\\_1 & English & USA    & R\\\\\n",
       "\t4806 & Color & Paul Fox     & Jeff Seymour & Horror\\textbar{}Thriller & Dov Tiefenbach  & The Dark HoursÂ  & Gordon Currie & brain tumor\\textbar{}champagne\\textbar{}game\\textbar{}psychiatrist\\textbar{}weekend       & http://www.imdb.com/title/tt0402249/?ref\\_=fn\\_tt\\_tt\\_1 & English & Canada & R\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 12\n",
       "\n",
       "| <!--/--> | color &lt;fct&gt; | director_name &lt;fct&gt; | actor_2_name &lt;fct&gt; | genres &lt;fct&gt; | actor_1_name &lt;fct&gt; | movie_title &lt;fct&gt; | actor_3_name &lt;fct&gt; | plot_keywords &lt;fct&gt; | movie_imdb_link &lt;fct&gt; | language &lt;fct&gt; | country &lt;fct&gt; | content_rating &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3925 | Color | Oliver Stone | Zach Grenier | Drama           | Michael Wincott | Talk RadioÂ      | Bill Johnson  | listener|neo nazi|radio|radio station|radio talk show | http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1 | English | USA    | R |\n",
       "| 4806 | Color | Paul Fox     | Jeff Seymour | Horror|Thriller | Dov Tiefenbach  | The Dark HoursÂ  | Gordon Currie | brain tumor|champagne|game|psychiatrist|weekend       | http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1 | English | Canada | R |\n",
       "\n"
      ],
      "text/plain": [
       "     color director_name actor_2_name genres          actor_1_name   \n",
       "3925 Color Oliver Stone  Zach Grenier Drama           Michael Wincott\n",
       "4806 Color Paul Fox      Jeff Seymour Horror|Thriller Dov Tiefenbach \n",
       "     movie_title      actor_3_name \n",
       "3925 Talk RadioÂ      Bill Johnson \n",
       "4806 The Dark HoursÂ  Gordon Currie\n",
       "     plot_keywords                                        \n",
       "3925 listener|neo nazi|radio|radio station|radio talk show\n",
       "4806 brain tumor|champagne|game|psychiatrist|weekend      \n",
       "     movie_imdb_link                                      language country\n",
       "3925 http://www.imdb.com/title/tt0096219/?ref_=fn_tt_tt_1 English  USA    \n",
       "4806 http://www.imdb.com/title/tt0402249/?ref_=fn_tt_tt_1 English  Canada \n",
       "     content_rating\n",
       "3925 R             \n",
       "4806 R             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_factor[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us keep four of them: Color, language, country and content_rating, and transform them with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_keep<-c(\"color\",\"language\",\"country\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"\n",
      "Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"\n",
      "Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"\n",
      "Warning message in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE):\n",
      "\"non-list contrasts argument ignored\"\n"
     ]
    }
   ],
   "source": [
    "data_factor_onehot <- dummy.data.frame(data_factor[,variables_to_keep], sep=\"_\")\n",
    "# Concerning the warnings: https://stackoverflow.com/questions/56637183/warning-message-dummy-from-dummies-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1000</li><li>82</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 82\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 82\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 82</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>color_</th><th scope=col>color_ Black and White</th><th scope=col>color_Color</th><th scope=col>language_</th><th scope=col>language_Aboriginal</th><th scope=col>language_Arabic</th><th scope=col>language_Cantonese</th><th scope=col>language_Danish</th><th scope=col>language_Dari</th><th scope=col>language_Dutch</th><th scope=col>language_Dzongkha</th><th scope=col>language_English</th><th scope=col>language_French</th><th scope=col>language_German</th><th scope=col>language_Hebrew</th><th scope=col>language_Hindi</th><th scope=col>language_Icelandic</th><th scope=col>language_Italian</th><th scope=col>language_Kazakh</th><th scope=col>language_Mandarin</th><th scope=col>language_Norwegian</th><th scope=col>language_Panjabi</th><th scope=col>language_Persian</th><th scope=col>language_Polish</th><th scope=col>language_Portuguese</th><th scope=col>...</th><th scope=col>country_South Africa</th><th scope=col>country_South Korea</th><th scope=col>country_Soviet Union</th><th scope=col>country_Spain</th><th scope=col>country_Switzerland</th><th scope=col>country_UK</th><th scope=col>country_United Arab Emirates</th><th scope=col>country_USA</th><th scope=col>content_rating_</th><th scope=col>content_rating_Approved</th><th scope=col>content_rating_G</th><th scope=col>content_rating_GP</th><th scope=col>content_rating_M</th><th scope=col>content_rating_NC-17</th><th scope=col>content_rating_Not Rated</th><th scope=col>content_rating_Passed</th><th scope=col>content_rating_PG</th><th scope=col>content_rating_PG-13</th><th scope=col>content_rating_R</th><th scope=col>content_rating_TV-14</th><th scope=col>content_rating_TV-G</th><th scope=col>content_rating_TV-MA</th><th scope=col>content_rating_TV-PG</th><th scope=col>content_rating_Unrated</th><th scope=col>content_rating_X</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>...</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3925</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4806</th><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>...</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 82\n",
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & color\\_ & color\\_ Black and White & color\\_Color & language\\_ & language\\_Aboriginal & language\\_Arabic & language\\_Cantonese & language\\_Danish & language\\_Dari & language\\_Dutch & language\\_Dzongkha & language\\_English & language\\_French & language\\_German & language\\_Hebrew & language\\_Hindi & language\\_Icelandic & language\\_Italian & language\\_Kazakh & language\\_Mandarin & language\\_Norwegian & language\\_Panjabi & language\\_Persian & language\\_Polish & language\\_Portuguese & ... & country\\_South Africa & country\\_South Korea & country\\_Soviet Union & country\\_Spain & country\\_Switzerland & country\\_UK & country\\_United Arab Emirates & country\\_USA & content\\_rating\\_ & content\\_rating\\_Approved & content\\_rating\\_G & content\\_rating\\_GP & content\\_rating\\_M & content\\_rating\\_NC-17 & content\\_rating\\_Not Rated & content\\_rating\\_Passed & content\\_rating\\_PG & content\\_rating\\_PG-13 & content\\_rating\\_R & content\\_rating\\_TV-14 & content\\_rating\\_TV-G & content\\_rating\\_TV-MA & content\\_rating\\_TV-PG & content\\_rating\\_Unrated & content\\_rating\\_X\\\\\n",
       "  & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & ... & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t3925 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t4806 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & ... & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 82\n",
       "\n",
       "| <!--/--> | color_ &lt;int&gt; | color_ Black and White &lt;int&gt; | color_Color &lt;int&gt; | language_ &lt;int&gt; | language_Aboriginal &lt;int&gt; | language_Arabic &lt;int&gt; | language_Cantonese &lt;int&gt; | language_Danish &lt;int&gt; | language_Dari &lt;int&gt; | language_Dutch &lt;int&gt; | language_Dzongkha &lt;int&gt; | language_English &lt;int&gt; | language_French &lt;int&gt; | language_German &lt;int&gt; | language_Hebrew &lt;int&gt; | language_Hindi &lt;int&gt; | language_Icelandic &lt;int&gt; | language_Italian &lt;int&gt; | language_Kazakh &lt;int&gt; | language_Mandarin &lt;int&gt; | language_Norwegian &lt;int&gt; | language_Panjabi &lt;int&gt; | language_Persian &lt;int&gt; | language_Polish &lt;int&gt; | language_Portuguese &lt;int&gt; | ... ... | country_South Africa &lt;int&gt; | country_South Korea &lt;int&gt; | country_Soviet Union &lt;int&gt; | country_Spain &lt;int&gt; | country_Switzerland &lt;int&gt; | country_UK &lt;int&gt; | country_United Arab Emirates &lt;int&gt; | country_USA &lt;int&gt; | content_rating_ &lt;int&gt; | content_rating_Approved &lt;int&gt; | content_rating_G &lt;int&gt; | content_rating_GP &lt;int&gt; | content_rating_M &lt;int&gt; | content_rating_NC-17 &lt;int&gt; | content_rating_Not Rated &lt;int&gt; | content_rating_Passed &lt;int&gt; | content_rating_PG &lt;int&gt; | content_rating_PG-13 &lt;int&gt; | content_rating_R &lt;int&gt; | content_rating_TV-14 &lt;int&gt; | content_rating_TV-G &lt;int&gt; | content_rating_TV-MA &lt;int&gt; | content_rating_TV-PG &lt;int&gt; | content_rating_Unrated &lt;int&gt; | content_rating_X &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 3925 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 4806 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "     color_ color_ Black and White color_Color language_ language_Aboriginal\n",
       "3925 0      0                      1           0         0                  \n",
       "4806 0      0                      1           0         0                  \n",
       "     language_Arabic language_Cantonese language_Danish language_Dari\n",
       "3925 0               0                  0               0            \n",
       "4806 0               0                  0               0            \n",
       "     language_Dutch language_Dzongkha language_English language_French\n",
       "3925 0              0                 1                0              \n",
       "4806 0              0                 1                0              \n",
       "     language_German language_Hebrew language_Hindi language_Icelandic\n",
       "3925 0               0               0              0                 \n",
       "4806 0               0               0              0                 \n",
       "     language_Italian language_Kazakh language_Mandarin language_Norwegian\n",
       "3925 0                0               0                 0                 \n",
       "4806 0                0               0                 0                 \n",
       "     language_Panjabi language_Persian language_Polish language_Portuguese ...\n",
       "3925 0                0                0               0                   ...\n",
       "4806 0                0                0               0                   ...\n",
       "     country_South Africa country_South Korea country_Soviet Union\n",
       "3925 0                    0                   0                   \n",
       "4806 0                    0                   0                   \n",
       "     country_Spain country_Switzerland country_UK country_United Arab Emirates\n",
       "3925 0             0                   0          0                           \n",
       "4806 0             0                   0          0                           \n",
       "     country_USA content_rating_ content_rating_Approved content_rating_G\n",
       "3925 1           0               0                       0               \n",
       "4806 0           0               0                       0               \n",
       "     content_rating_GP content_rating_M content_rating_NC-17\n",
       "3925 0                 0                0                   \n",
       "4806 0                 0                0                   \n",
       "     content_rating_Not Rated content_rating_Passed content_rating_PG\n",
       "3925 0                        0                     0                \n",
       "4806 0                        0                     0                \n",
       "     content_rating_PG-13 content_rating_R content_rating_TV-14\n",
       "3925 0                    1                0                   \n",
       "4806 0                    1                0                   \n",
       "     content_rating_TV-G content_rating_TV-MA content_rating_TV-PG\n",
       "3925 0                   0                    0                   \n",
       "4806 0                   0                    0                   \n",
       "     content_rating_Unrated content_rating_X\n",
       "3925 0                      0               \n",
       "4806 0                      0               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_factor_onehot[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These could be added to the previously preprocessed dataset, and used to further improve the prediction accuracy using the feature selection/ensemble techniques seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-cbind(data_preprocessed,data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1000</li><li>98</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 98\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 98\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " num_critic_for_reviews    duration   director_facebook_likes\n",
       " Min.   :  1.0          Min.   :  7   Min.   :    0.0        \n",
       " 1st Qu.: 48.0          1st Qu.: 93   1st Qu.:    7.0        \n",
       " Median :105.5          Median :103   Median :   48.5        \n",
       " Mean   :135.1          Mean   :106   Mean   :  669.3        \n",
       " 3rd Qu.:181.0          3rd Qu.:116   3rd Qu.:  234.0        \n",
       " Max.   :765.0          Max.   :511   Max.   :21000.0        \n",
       " actor_3_facebook_likes actor_1_facebook_likes     gross          \n",
       " Min.   :    0.0        Min.   :    0.0        Min.   :      703  \n",
       " 1st Qu.:  120.0        1st Qu.:  623.8        1st Qu.:  9158619  \n",
       " Median :  397.5        Median :  982.0        Median : 38108330  \n",
       " Mean   :  602.2        Mean   : 5950.9        Mean   : 46927291  \n",
       " 3rd Qu.:  642.0        3rd Qu.:11000.0        3rd Qu.: 47159944  \n",
       " Max.   :19000.0        Max.   :49000.0        Max.   :658672302  \n",
       " num_voted_users  cast_total_facebook_likes facenumber_in_poster\n",
       " Min.   :     5   Min.   :    0             Min.   : 0.000      \n",
       " 1st Qu.:  7110   1st Qu.: 1466             1st Qu.: 0.000      \n",
       " Median : 31625   Median : 3142             Median : 1.000      \n",
       " Mean   : 76398   Mean   : 9103             Mean   : 1.394      \n",
       " 3rd Qu.: 87767   3rd Qu.:13884             3rd Qu.: 2.000      \n",
       " Max.   :955174   Max.   :77823             Max.   :31.000      \n",
       " num_user_for_reviews     budget            title_year   actor_2_facebook_likes\n",
       " Min.   :   1.0       Min.   :     3250   Min.   :1916   Min.   :    0.0       \n",
       " 1st Qu.:  61.0       1st Qu.:  6500000   1st Qu.:1999   1st Qu.:  301.5       \n",
       " Median : 156.0       Median : 22000000   Median :2005   Median :  605.0       \n",
       " Mean   : 257.5       Mean   : 31645256   Mean   :2002   Mean   : 1720.3       \n",
       " 3rd Qu.: 315.2       3rd Qu.: 37000000   3rd Qu.:2010   3rd Qu.:  936.5       \n",
       " Max.   :3597.0       Max.   :260000000   Max.   :2016   Max.   :29000.0       \n",
       "   imdb_score     aspect_ratio    movie_facebook_likes     color_     \n",
       " Min.   :1.900   Min.   : 1.330   Min.   :     0       Min.   :0.000  \n",
       " 1st Qu.:5.800   1st Qu.: 1.850   1st Qu.:     0       1st Qu.:0.000  \n",
       " Median :6.500   Median : 2.289   Median :    65       Median :0.000  \n",
       " Mean   :6.426   Mean   : 2.289   Mean   :  6947       Mean   :0.004  \n",
       " 3rd Qu.:7.200   3rd Qu.: 2.350   3rd Qu.:  1000       3rd Qu.:0.000  \n",
       " Max.   :8.900   Max.   :16.000   Max.   :199000       Max.   :1.000  \n",
       " color_ Black and White  color_Color      language_     language_Aboriginal\n",
       " Min.   :0.000          Min.   :0.000   Min.   :0.000   Min.   :0.000      \n",
       " 1st Qu.:0.000          1st Qu.:1.000   1st Qu.:0.000   1st Qu.:0.000      \n",
       " Median :0.000          Median :1.000   Median :0.000   Median :0.000      \n",
       " Mean   :0.037          Mean   :0.959   Mean   :0.004   Mean   :0.002      \n",
       " 3rd Qu.:0.000          3rd Qu.:1.000   3rd Qu.:0.000   3rd Qu.:0.000      \n",
       " Max.   :1.000          Max.   :1.000   Max.   :1.000   Max.   :1.000      \n",
       " language_Arabic language_Cantonese language_Danish language_Dari  \n",
       " Min.   :0.000   Min.   :0.000      Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000      1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000      Median :0.000   Median :0.000  \n",
       " Mean   :0.001   Mean   :0.003      Mean   :0.001   Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000      3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000      Max.   :1.000   Max.   :1.000  \n",
       " language_Dutch  language_Dzongkha language_English language_French\n",
       " Min.   :0.000   Min.   :0.000     Min.   :0.000    Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000     1st Qu.:1.000    1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000     Median :1.000    Median :0.000  \n",
       " Mean   :0.001   Mean   :0.001     Mean   :0.934    Mean   :0.015  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000     3rd Qu.:1.000    3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000     Max.   :1.000    Max.   :1.000  \n",
       " language_German language_Hebrew language_Hindi  language_Icelandic\n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000     \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000     \n",
       " Median :0.000   Median :0.000   Median :0.000   Median :0.000     \n",
       " Mean   :0.004   Mean   :0.001   Mean   :0.005   Mean   :0.001     \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000     \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000   Max.   :1.000     \n",
       " language_Italian language_Kazakh language_Mandarin language_Norwegian\n",
       " Min.   :0.000    Min.   :0.000   Min.   :0.000     Min.   :0.000     \n",
       " 1st Qu.:0.000    1st Qu.:0.000   1st Qu.:0.000     1st Qu.:0.000     \n",
       " Median :0.000    Median :0.000   Median :0.000     Median :0.000     \n",
       " Mean   :0.002    Mean   :0.001   Mean   :0.004     Mean   :0.001     \n",
       " 3rd Qu.:0.000    3rd Qu.:0.000   3rd Qu.:0.000     3rd Qu.:0.000     \n",
       " Max.   :1.000    Max.   :1.000   Max.   :1.000     Max.   :1.000     \n",
       " language_Panjabi language_Persian language_Polish language_Portuguese\n",
       " Min.   :0.000    Min.   :0.000    Min.   :0.000   Min.   :0.000      \n",
       " 1st Qu.:0.000    1st Qu.:0.000    1st Qu.:0.000   1st Qu.:0.000      \n",
       " Median :0.000    Median :0.000    Median :0.000   Median :0.000      \n",
       " Mean   :0.001    Mean   :0.002    Mean   :0.001   Mean   :0.004      \n",
       " 3rd Qu.:0.000    3rd Qu.:0.000    3rd Qu.:0.000   3rd Qu.:0.000      \n",
       " Max.   :1.000    Max.   :1.000    Max.   :1.000   Max.   :1.000      \n",
       " language_Romanian language_Russian language_Spanish language_Telugu\n",
       " Min.   :0.000     Min.   :0.000    Min.   :0.000    Min.   :0.000  \n",
       " 1st Qu.:0.000     1st Qu.:0.000    1st Qu.:0.000    1st Qu.:0.000  \n",
       " Median :0.000     Median :0.000    Median :0.000    Median :0.000  \n",
       " Mean   :0.001     Mean   :0.003    Mean   :0.005    Mean   :0.001  \n",
       " 3rd Qu.:0.000     3rd Qu.:0.000    3rd Qu.:0.000    3rd Qu.:0.000  \n",
       " Max.   :1.000     Max.   :1.000    Max.   :1.000    Max.   :1.000  \n",
       " country_Afghanistan country_Australia country_Brazil  country_Canada \n",
       " Min.   :0.000       Min.   :0.000     Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000       1st Qu.:0.000     1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000       Median :0.000     Median :0.000   Median :0.000  \n",
       " Mean   :0.001       Mean   :0.018     Mean   :0.004   Mean   :0.027  \n",
       " 3rd Qu.:0.000       3rd Qu.:0.000     3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000       Max.   :1.000     Max.   :1.000   Max.   :1.000  \n",
       " country_Chile   country_China   country_Czech Republic country_Denmark\n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000          Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000          1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000   Median :0.000          Median :0.000  \n",
       " Mean   :0.001   Mean   :0.004   Mean   :0.001          Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000          3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000          Max.   :1.000  \n",
       " country_France  country_Germany country_Hong Kong country_Iceland\n",
       " Min.   :0.000   Min.   :0.00    Min.   :0.000     Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.00    1st Qu.:0.000     1st Qu.:0.000  \n",
       " Median :0.000   Median :0.00    Median :0.000     Median :0.000  \n",
       " Mean   :0.024   Mean   :0.02    Mean   :0.003     Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.00    3rd Qu.:0.000     3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.00    Max.   :1.000     Max.   :1.000  \n",
       " country_India    country_Iran   country_Ireland country_Italy  \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000   Median :0.000   Median :0.000  \n",
       " Mean   :0.005   Mean   :0.002   Mean   :0.003   Mean   :0.006  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000   Max.   :1.000  \n",
       " country_Japan   country_Mexico  country_Netherlands country_New Zealand\n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000       Min.   :0.000      \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000       1st Qu.:0.000      \n",
       " Median :0.000   Median :0.000   Median :0.000       Median :0.000      \n",
       " Mean   :0.001   Mean   :0.001   Mean   :0.001       Mean   :0.003      \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000       3rd Qu.:0.000      \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000       Max.   :1.000      \n",
       " country_Nigeria country_Norway  country_Official site country_Panama \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000         Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000         1st Qu.:0.000  \n",
       " Median :0.000   Median :0.000   Median :0.000         Median :0.000  \n",
       " Mean   :0.001   Mean   :0.002   Mean   :0.001         Mean   :0.001  \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000         3rd Qu.:0.000  \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000         Max.   :1.000  \n",
       " country_Poland  country_Romania country_Russia  country_Slovakia\n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000   \n",
       " 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.000   \n",
       " Median :0.000   Median :0.000   Median :0.000   Median :0.000   \n",
       " Mean   :0.001   Mean   :0.001   Mean   :0.003   Mean   :0.001   \n",
       " 3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000   3rd Qu.:0.000   \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.000   Max.   :1.000   \n",
       " country_South Africa country_South Korea country_Soviet Union country_Spain  \n",
       " Min.   :0.000        Min.   :0.000       Min.   :0.000        Min.   :0.000  \n",
       " 1st Qu.:0.000        1st Qu.:0.000       1st Qu.:0.000        1st Qu.:0.000  \n",
       " Median :0.000        Median :0.000       Median :0.000        Median :0.000  \n",
       " Mean   :0.001        Mean   :0.002       Mean   :0.001        Mean   :0.006  \n",
       " 3rd Qu.:0.000        3rd Qu.:0.000       3rd Qu.:0.000        3rd Qu.:0.000  \n",
       " Max.   :1.000        Max.   :1.000       Max.   :1.000        Max.   :1.000  \n",
       " country_Switzerland   country_UK    country_United Arab Emirates\n",
       " Min.   :0.000       Min.   :0.000   Min.   :0.000               \n",
       " 1st Qu.:0.000       1st Qu.:0.000   1st Qu.:0.000               \n",
       " Median :0.000       Median :0.000   Median :0.000               \n",
       " Mean   :0.001       Mean   :0.098   Mean   :0.001               \n",
       " 3rd Qu.:0.000       3rd Qu.:0.000   3rd Qu.:0.000               \n",
       " Max.   :1.000       Max.   :1.000   Max.   :1.000               \n",
       "  country_USA    content_rating_ content_rating_Approved content_rating_G\n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.00            Min.   :0.000   \n",
       " 1st Qu.:1.000   1st Qu.:0.000   1st Qu.:0.00            1st Qu.:0.000   \n",
       " Median :1.000   Median :0.000   Median :0.00            Median :0.000   \n",
       " Mean   :0.752   Mean   :0.078   Mean   :0.01            Mean   :0.011   \n",
       " 3rd Qu.:1.000   3rd Qu.:0.000   3rd Qu.:0.00            3rd Qu.:0.000   \n",
       " Max.   :1.000   Max.   :1.000   Max.   :1.00            Max.   :1.000   \n",
       " content_rating_GP content_rating_M content_rating_NC-17\n",
       " Min.   :0.000     Min.   :0.000    Min.   :0.000       \n",
       " 1st Qu.:0.000     1st Qu.:0.000    1st Qu.:0.000       \n",
       " Median :0.000     Median :0.000    Median :0.000       \n",
       " Mean   :0.004     Mean   :0.001    Mean   :0.001       \n",
       " 3rd Qu.:0.000     3rd Qu.:0.000    3rd Qu.:0.000       \n",
       " Max.   :1.000     Max.   :1.000    Max.   :1.000       \n",
       " content_rating_Not Rated content_rating_Passed content_rating_PG\n",
       " Min.   :0.000            Min.   :0.000         Min.   :0.000    \n",
       " 1st Qu.:0.000            1st Qu.:0.000         1st Qu.:0.000    \n",
       " Median :0.000            Median :0.000         Median :0.000    \n",
       " Mean   :0.021            Mean   :0.001         Mean   :0.145    \n",
       " 3rd Qu.:0.000            3rd Qu.:0.000         3rd Qu.:0.000    \n",
       " Max.   :1.000            Max.   :1.000         Max.   :1.000    \n",
       " content_rating_PG-13 content_rating_R content_rating_TV-14 content_rating_TV-G\n",
       " Min.   :0.000        Min.   :0.000    Min.   :0.000        Min.   :0.000      \n",
       " 1st Qu.:0.000        1st Qu.:0.000    1st Qu.:0.000        1st Qu.:0.000      \n",
       " Median :0.000        Median :0.000    Median :0.000        Median :0.000      \n",
       " Mean   :0.264        Mean   :0.433    Mean   :0.002        Mean   :0.004      \n",
       " 3rd Qu.:1.000        3rd Qu.:1.000    3rd Qu.:0.000        3rd Qu.:0.000      \n",
       " Max.   :1.000        Max.   :1.000    Max.   :1.000        Max.   :1.000      \n",
       " content_rating_TV-MA content_rating_TV-PG content_rating_Unrated\n",
       " Min.   :0.000        Min.   :0.000        Min.   :0.000         \n",
       " 1st Qu.:0.000        1st Qu.:0.000        1st Qu.:0.000         \n",
       " Median :0.000        Median :0.000        Median :0.000         \n",
       " Mean   :0.006        Mean   :0.006        Mean   :0.011         \n",
       " 3rd Qu.:0.000        3rd Qu.:0.000        3rd Qu.:0.000         \n",
       " Max.   :1.000        Max.   :1.000        Max.   :1.000         \n",
       " content_rating_X\n",
       " Min.   :0.000   \n",
       " 1st Qu.:0.000   \n",
       " Median :0.000   \n",
       " Mean   :0.002   \n",
       " 3rd Qu.:0.000   \n",
       " Max.   :1.000   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other predictive models\n",
    "\n",
    "Other models could be used, for example support vector machines, neural networks, K-nearest neighbors (using the `svm`, `nnt`or `lazy` functions from the `e1071`, `nnet` or `lazy` packages, respectively). Note that scaling the data is usually necessary when using neural networks and K-nearest neighbors approaches.\n",
    "\n",
    "Is the usage of different models improving the predictive performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(c(\"e1071\",\"nnet\",\"lazy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X<-data_preprocessed_extended[,setdiff(colnames(data_preprocessed_extended),\"imdb_score\")]\n",
    "Y<-data_preprocessed_extended[,\"imdb_score\"]\n",
    "\n",
    "colnames(X) <- gsub(colnames(X),pattern = \" \", replacement = \"_\")\n",
    "colnames(X) <- gsub(colnames(X),pattern = \"-\", replacement = \"_\")\n",
    "\n",
    "N<-nrow(X)    #Number of examples\n",
    "n<-ncol(X)    #Number of input variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1000</li><li>97</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 97\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 97\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   97"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1000"
      ],
      "text/latex": [
       "1000"
      ],
      "text/markdown": [
       "1000"
      ],
      "text/plain": [
       "[1] 1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(X)\n",
    "length(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'e1071' was built under R version 4.0.5\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'language_Icelandic' and 'language_Polish' and 'country_Iceland' and 'country_Panama' and 'country_Poland' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'country_South_Africa' and 'country_Soviet_Union' and 'country_Switzerland' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'country_Slovakia' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'language_Dari' and 'language_Hebrew' and 'country_Afghanistan' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'language_Kazakh' and 'language_Romanian' and 'country_Romania' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'language_Norwegian' and 'language_Panjabi' and 'language_Telugu' and 'country_Mexico' and 'country_Nigeria' and 'country_Norway' and 'content_rating_M' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'language_Arabic' and 'language_Dutch' and 'country_Chile' and 'country_Czech_Republic' and 'country_Netherlands' and 'country_United_Arab_Emirates' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'language_Aboriginal' and 'country_Japan' and 'country_Official_site' and 'content_rating_NC_17' and 'content_rating_Passed' constant. Cannot scale data.\"\n",
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'language_Danish' and 'language_Dzongkha' and 'country_Denmark' constant. Cannot scale data.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CV error= 1.2294  ; std dev= 0.2539\"\n"
     ]
    }
   ],
   "source": [
    "library(e1071)\n",
    "\n",
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-numeric(CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "     idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "     X_ts<-X[idx_ts,]  \n",
    "     Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "     idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "     X_tr<-X[idx_tr,]\n",
    "     Y_tr<-Y[idx_tr]                          \n",
    "     \n",
    "     DS<-cbind(X_tr,imdb_score=Y_tr)\n",
    "    \n",
    "     # Model fit (using lm function)\n",
    "     model<- svm(imdb_score~.,DS)\n",
    "     \n",
    "     # Model prediction \n",
    "     Y_hat_ts<- predict(model,X_ts)\n",
    "     \n",
    "     # Cross validation error = Mean Squared Error\n",
    "     CV_err[i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV_err),digits=4), \" ; std dev=\",round(sd(CV_err),digits=4)))\n",
    "\n",
    "CV_err_svm_single_model <- CV_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"#Features:  1  ; CV error= 1.0429  ; std dev= 0.1948\" \n",
      " [2] \"#Features:  2  ; CV error= 1.0392  ; std dev= 0.2102\" \n",
      " [3] \"#Features:  3  ; CV error= 1.0216  ; std dev= 0.2077\" \n",
      " [4] \"#Features:  4  ; CV error= 1.0183  ; std dev= 0.2057\" \n",
      " [5] \"#Features:  5  ; CV error= 0.9436  ; std dev= 0.1987\" \n",
      " [6] \"#Features:  6  ; CV error= 0.9177  ; std dev= 0.2176\" \n",
      " [7] \"#Features:  7  ; CV error= 0.8822  ; std dev= 0.1769\" \n",
      " [8] \"#Features:  8  ; CV error= 0.8725  ; std dev= 0.1572\" \n",
      " [9] \"#Features:  9  ; CV error= 0.8679  ; std dev= 0.1512\" \n",
      "[10] \"#Features:  10  ; CV error= 0.8644  ; std dev= 0.1478\"\n"
     ]
    }
   ],
   "source": [
    "# drop = F is used to preserve the structure of the data as data.frame (see https://www.r-bloggers.com/2018/02/r-tip-use-drop-false-with-data-frames/)\n",
    "\n",
    "CV_folds <- 10\n",
    "n_variables <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-matrix(0,nrow=n_variables,ncol=CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "    \n",
    "    idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "    X_ts<-X[idx_ts,]  \n",
    "    Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "    idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "    X_tr<-X[idx_tr,]\n",
    "    Y_tr<-Y[idx_tr]                          \n",
    "    \n",
    "    # Computing the correlation between input variables and output variable on the training set\n",
    "    correlation<-abs(cor(X_tr,Y_tr))\n",
    "    \n",
    "    # Initialization : No variables are selected and all the variables are candidates\n",
    "    selected<-c()\n",
    "    candidates<-1:n\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n_variables) {\n",
    "        redundancy_score<-numeric(length(candidates))\n",
    "        \n",
    "        if (length(selected)>0) {\n",
    "            # Compute the correlation between the selected variables and the candidates on the training set\n",
    "            cor_selected_candidates<-cor(X_tr[,selected,drop=F],X_tr[,candidates,drop=F])\n",
    "            # Compute the mean correlation for each candidate variable, across the selected variables\n",
    "            redundancy_score<-apply(cor_selected_candidates,2,mean)\n",
    "        }\n",
    "        \n",
    "        # mRMR: minimum Redundancy Maximum Relevancy\n",
    "        mRMR_score<-correlation[candidates]-redundancy_score\n",
    "        \n",
    "        # Select the candidate variable that maximises the mRMR score\n",
    "        selected_current<-candidates[which.max(mRMR_score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        \n",
    "        # Remove the selected variables from the candidates\n",
    "        candidates<-setdiff(candidates,selected_current)\n",
    "    }\n",
    "    \n",
    "    ranking <- selected\n",
    "     \n",
    "    for (nb_features in 1:n_variables) {\n",
    "        # Create a dataset including only the first nb_features selected variables\n",
    "        DS<-cbind(X_tr[,ranking[1:nb_features],drop=F],imdb_score=Y_tr)\n",
    "        \n",
    "        # Model fit (using lm function)\n",
    "        model<- svm(imdb_score~.,DS)\n",
    "     \n",
    "        # Model prediction \n",
    "        Y_hat_ts<- predict(model,X_ts)\n",
    "        \n",
    "        # Cross-validation error = MSE\n",
    "        CV_err[nb_features,i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n_variables),\" ; CV error=\",round(apply(CV_err,1,mean),digits=4), \" ; std dev=\",round(apply(CV_err,1,sd),digits=4)))\n",
    "\n",
    "CV_err_svm_single_model_fs <- CV_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'nnet' was built under R version 4.0.5\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CV error= 1.2316  ; std dev= 0.21\"\n"
     ]
    }
   ],
   "source": [
    "library(nnet)\n",
    "\n",
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-numeric(CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "     idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "     X_ts<-X[idx_ts,]  \n",
    "     Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "     idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "     X_tr<-X[idx_tr,]\n",
    "     Y_tr<-Y[idx_tr]                          \n",
    "     \n",
    "     DS<-cbind(X_tr,imdb_score=Y_tr/10) # The output variable is rescaled to be in 0-1 range\n",
    "    \n",
    "     # Model fit (using nnet function)\n",
    "     model <- nnet(imdb_score ~ .,DS,skip=FALSE,\n",
    "                       size=10, maxit=5000,trace=F,rang=0.2,MaxNWts=10000)\n",
    "     \n",
    "     # Model prediction (multiplied by 10 to rescale (0,1) -> (0,10))\n",
    "     Y_hat_ts<- predict(model,X_ts)*10\n",
    "     \n",
    "     # Cross validation error = Mean Squared Error\n",
    "     CV_err[i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV_err),digits=4), \" ; std dev=\",round(sd(CV_err),digits=4)))\n",
    "\n",
    "CV_err_nnet_single_model <- CV_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"#Features:  1  ; CV error= 1.0992  ; std dev= 0.2409\" \n",
      " [2] \"#Features:  2  ; CV error= 1.1306  ; std dev= 0.1908\" \n",
      " [3] \"#Features:  3  ; CV error= 1.1262  ; std dev= 0.1337\" \n",
      " [4] \"#Features:  4  ; CV error= 1.1357  ; std dev= 0.2034\" \n",
      " [5] \"#Features:  5  ; CV error= 1.0928  ; std dev= 0.2276\" \n",
      " [6] \"#Features:  6  ; CV error= 1.1739  ; std dev= 0.2394\" \n",
      " [7] \"#Features:  7  ; CV error= 1.129  ; std dev= 0.1959\"  \n",
      " [8] \"#Features:  8  ; CV error= 1.0872  ; std dev= 0.1539\" \n",
      " [9] \"#Features:  9  ; CV error= 1.151  ; std dev= 0.1369\"  \n",
      "[10] \"#Features:  10  ; CV error= 1.1299  ; std dev= 0.1466\"\n"
     ]
    }
   ],
   "source": [
    "# drop = F is used to preserve the structure of the data as data.frame (see https://www.r-bloggers.com/2018/02/r-tip-use-drop-false-with-data-frames/)\n",
    "\n",
    "CV_folds <- 10\n",
    "n_variables <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-matrix(0,nrow=n_variables,ncol=CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "    \n",
    "    idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "    X_ts<-X[idx_ts,]  \n",
    "    Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "    idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "    X_tr<-X[idx_tr,]\n",
    "    Y_tr<-Y[idx_tr]                          \n",
    "    \n",
    "    # Computing the correlation between input variables and output variable on the training set\n",
    "    correlation<-abs(cor(X_tr,Y_tr))\n",
    "    \n",
    "    # Initialization : No variables are selected and all the variables are candidates\n",
    "    selected<-c()\n",
    "    candidates<-1:n\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n_variables) {\n",
    "        redundancy_score<-numeric(length(candidates))\n",
    "        \n",
    "        if (length(selected)>0) {\n",
    "            # Compute the correlation between the selected variables and the candidates on the training set\n",
    "            cor_selected_candidates<-cor(X_tr[,selected,drop=F],X_tr[,candidates,drop=F])\n",
    "            # Compute the mean correlation for each candidate variable, across the selected variables\n",
    "            redundancy_score<-apply(cor_selected_candidates,2,mean)\n",
    "        }\n",
    "        \n",
    "        # mRMR: minimum Redundancy Maximum Relevancy\n",
    "        mRMR_score<-correlation[candidates]-redundancy_score\n",
    "        \n",
    "        # Select the candidate variable that maximises the mRMR score\n",
    "        selected_current<-candidates[which.max(mRMR_score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        \n",
    "        # Remove the selected variables from the candidates\n",
    "        candidates<-setdiff(candidates,selected_current)\n",
    "    }\n",
    "    \n",
    "    ranking <- selected\n",
    "     \n",
    "    for (nb_features in 1:n_variables) {\n",
    "        # Create a dataset including only the first nb_features selected variables\n",
    "        # The output variable is rescaled to be in 0-1 range\n",
    "        DS<-cbind(X_tr[,ranking[1:nb_features],drop=F],imdb_score=Y_tr/10)\n",
    "        \n",
    "        # Model fit (using nnet function)\n",
    "        model <- nnet(imdb_score ~ .,DS,skip=FALSE,\n",
    "                       size=10, maxit=500,trace=F,rang=0.2,MaxNWts=10000)\n",
    "     \n",
    "        # Model prediction (multiplied by 10 to rescale (0,1) -> (0,10))\n",
    "        Y_hat_ts<- predict(model,X_ts)*10\n",
    "        \n",
    "        # Cross-validation error = MSE\n",
    "        CV_err[nb_features,i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n_variables),\" ; CV error=\",round(apply(CV_err,1,mean),digits=4), \" ; std dev=\",round(apply(CV_err,1,sd),digits=4)))\n",
    "\n",
    "CV_err_nnet_single_model_fs <- CV_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"CV error= 1.14682710043345e+23  ; std dev= 2.56427269671226e+23\"\n"
     ]
    }
   ],
   "source": [
    "library(lazy)\n",
    "\n",
    "CV_folds <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-numeric(CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "     idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "     X_ts<-X[idx_ts,]  \n",
    "     Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "     idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "     X_tr<-X[idx_tr,]\n",
    "     Y_tr<-Y[idx_tr]                          \n",
    "     \n",
    "     DS<-cbind(X_tr,imdb_score=Y_tr)\n",
    "    \n",
    "     # Model fit (using lm function)\n",
    "     model<- lazy(imdb_score~.,DS)\n",
    "     \n",
    "     # Model prediction \n",
    "     Y_hat_ts<- predict(model,X_ts)$h\n",
    "     \n",
    "     # Cross validation error = Mean Squared Error\n",
    "     CV_err[i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV_err),digits=4), \" ; std dev=\",round(sd(CV_err),digits=4)))\n",
    "\n",
    "CV_err_lazy_single_model <- CV_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr, Y_tr):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n",
      "Warning message in cor(X_tr[, selected, drop = F], X_tr[, candidates, drop = F]):\n",
      "\"the standard deviation is zero\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"#Features:  1  ; CV error= 1.2513  ; std dev= 0.2353\"\n",
      " [2] \"#Features:  2  ; CV error= 1.3941  ; std dev= 0.3082\"\n",
      " [3] \"#Features:  3  ; CV error= 1.4098  ; std dev= 0.3334\"\n",
      " [4] \"#Features:  4  ; CV error= 1.5571  ; std dev= 0.455\" \n",
      " [5] \"#Features:  5  ; CV error= 1.5288  ; std dev= 0.3827\"\n",
      " [6] \"#Features:  6  ; CV error= 1.4941  ; std dev= 0.3574\"\n",
      " [7] \"#Features:  7  ; CV error= 1.6003  ; std dev= 0.4762\"\n",
      " [8] \"#Features:  8  ; CV error= 1.5657  ; std dev= 0.5639\"\n",
      " [9] \"#Features:  9  ; CV error= 1.568  ; std dev= 0.5733\" \n",
      "[10] \"#Features:  10  ; CV error= 1.6602  ; std dev= 0.655\"\n"
     ]
    }
   ],
   "source": [
    "# drop = F is used to preserve the structure of the data as data.frame (see https://www.r-bloggers.com/2018/02/r-tip-use-drop-false-with-data-frames/)\n",
    "\n",
    "CV_folds <- 10\n",
    "n_variables <- 10\n",
    "\n",
    "size_CV <-floor(N/CV_folds)\n",
    "\n",
    "CV_err<-matrix(0,nrow=n_variables,ncol=CV_folds)\n",
    "\n",
    "for (i in 1:CV_folds) {\n",
    "    \n",
    "    idx_ts<-(((i-1)*size_CV+1):(i*size_CV))  ### idx_ts represents the indices of the test set the i-th fold\n",
    "    X_ts<-X[idx_ts,]  \n",
    "    Y_ts<-Y[idx_ts]  \n",
    "     \n",
    "    idx_tr<-setdiff(1:N,idx_ts) ### idx_tr represents  indices of the training sefor the i-th fold\n",
    "    X_tr<-X[idx_tr,]\n",
    "    Y_tr<-Y[idx_tr]                          \n",
    "    \n",
    "    # Computing the correlation between input variables and output variable on the training set\n",
    "    correlation<-abs(cor(X_tr,Y_tr))\n",
    "    \n",
    "    # Initialization : No variables are selected and all the variables are candidates\n",
    "    selected<-c()\n",
    "    candidates<-1:n\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n_variables) {\n",
    "        redundancy_score<-numeric(length(candidates))\n",
    "        \n",
    "        if (length(selected)>0) {\n",
    "            # Compute the correlation between the selected variables and the candidates on the training set\n",
    "            cor_selected_candidates<-cor(X_tr[,selected,drop=F],X_tr[,candidates,drop=F])\n",
    "            # Compute the mean correlation for each candidate variable, across the selected variables\n",
    "            redundancy_score<-apply(cor_selected_candidates,2,mean)\n",
    "        }\n",
    "        \n",
    "        # mRMR: minimum Redundancy Maximum Relevancy\n",
    "        mRMR_score<-correlation[candidates]-redundancy_score\n",
    "        \n",
    "        # Select the candidate variable that maximises the mRMR score\n",
    "        selected_current<-candidates[which.max(mRMR_score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        \n",
    "        # Remove the selected variables from the candidates\n",
    "        candidates<-setdiff(candidates,selected_current)\n",
    "    }\n",
    "    \n",
    "    ranking <- selected\n",
    "     \n",
    "    for (nb_features in 1:n_variables) {\n",
    "        # Create a dataset including only the first nb_features selected variables\n",
    "        # The output variable is rescaled to be in 0-1 range\n",
    "        DS<-cbind(X_tr[,ranking[1:nb_features],drop=F],imdb_score=Y_tr)\n",
    "        \n",
    "        # Model fit (using lazy function)\n",
    "        model<- lazy(imdb_score~.,DS)\n",
    "     \n",
    "        # Model prediction \n",
    "        Y_hat_ts<- predict(model,X_ts)$h\n",
    "        \n",
    "        # Cross-validation error = MSE\n",
    "        CV_err[nb_features,i]<-mean((Y_hat_ts-Y_ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n_variables),\" ; CV error=\",round(apply(CV_err,1,mean),digits=4), \" ; std dev=\",round(apply(CV_err,1,sd),digits=4)))\n",
    "\n",
    "CV_err_lazy_single_model_fs <- CV_err"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
